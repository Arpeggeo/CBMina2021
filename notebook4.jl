### A Pluto.jl notebook ###
# v0.14.2

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : missing
        el
    end
end

# â•”â•â•¡ 32f6d41e-3248-4549-9546-53b34d5aa7c6
begin
	# instantiate environment
	using Pkg; Pkg.activate(@__DIR__); Pkg.instantiate()

	# load packages used in this notebook
	using GeoStats, Query
	using CSV, DataFrames
	using Distributions
	using PlutoUI
	using Plots
	using StatsPlots

	# default plot settings
	gr(format=:png)
end;

# â•”â•â•¡ 762a6e04-fcb7-4713-859d-fdbfe8ead1bc
html"""
<p style="background-color:lightgrey" xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">GeoStats.jl at CBMina</span> by <span property="cc:attributionName">JÃºlio Hoffimann & Franco Naghetini</span> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>
"""

# â•”â•â•¡ 32429926-f6c3-44b8-b012-d2c67cad0b6d
md"""
![geostats-logo](https://github.com/JuliaEarth/GeoStats.jl/blob/master/docs/src/assets/logo-text.svg?raw=true)

# GeostatÃ­stica moderna

Instrutores: [JÃºlio Hoffimann](https://juliohm.github.io) & [Franco Naghetini](https://github.com/fnaghetini)
"""

# â•”â•â•¡ 3c79e7aa-b316-4c4b-b44e-e73312085c20
md"""
## Aprendizado geoestatÃ­stico

Neste mÃ³dulo aprenderemos sobre esta nova Ã¡rea denominada **aprendizado geoestatÃ­stico** ([Hoffimann et al 2021](https://arxiv.org/abs/2102.08791)). Introduziremos os elementos do problema de aprendizado com **dados geoespaciais**, e veremos como a biblioteca [GeoStats.jl](https://github.com/JuliaEarth/GeoStats.jl) estÃ¡ na vanguarda desta tecnologia.

Existem questÃµes teÃ³ricas muito interessantes que nÃ£o cobriremos neste minicurso, e que estÃ£o sendo desenvolvidas ativamente no projeto. Nos concentraremos aqui em **exemplos prÃ¡ticos** para que vocÃª possa adaptar este notebook aos seus prÃ³prios desafios na mineraÃ§Ã£o.
"""

# â•”â•â•¡ 4a3fb559-73dd-41e0-8a11-993e5bf286bf
html"""
<iframe width="560" height="315" src="https://www.youtube.com/embed/6S_9GLMv3xI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
"""

# â•”â•â•¡ f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
md"""
Ao final deste mÃ³dulo vocÃª serÃ¡ capaz de:

- Identificar os **elementos do aprendizado geoestatÃ­stico** na mineraÃ§Ã£o
- Definir o **problema de aprendizado** de forma clara com o GeoStats.jl
- Resolver o problema com vÃ¡rios **modelos de aprendizado** disponÃ­veis

### Agenda

1. Aprendizado **geo**estatÃ­stico
    - O que Ã© aprendizado de mÃ¡quina (a.k.a. ML)?
    - A nova Ã¡rea de aprendizado **geo**estatÃ­stico
    - Os elementos do aprendizado **geo**estatÃ­stico
2. Exemplos prÃ¡ticos com o GeoStats.jl
    - Exemplo 1
    - Exemplo 2
"""

# â•”â•â•¡ 1856e01b-2d55-448d-8bdf-e59825934193
md"""
### 1. Aprendizado geoestatÃ­stico

#### O que Ã© o aprendizado de mÃ¡quina?

Antes de podermos entender o problema de aprendizado **geo**estatÃ­stico, isto Ã©, o problema de aprendizado com dados **geoespacias**, precisamos entender o problema mais simples de **aprendizado de mÃ¡quina** introduzido na ciÃªncia da computaÃ§Ã£o na Ã¡rea de **inteligÃªncia artificial**.

Nessa Ã¡rea, buscam-se criar tecnologias capazes de "imitar" a inteligÃªncia humana. Ao invÃ©s de tentarmos definir inteligÃªncia, vamos nos concentrar em duas habilidades que nÃ³s humanos exercermos todo dia:

1. A habilidade de **raciocinar sobre fatos**
2. A habilidade **aprender com experiÃªncia**

A habilidade de **raciocÃ­nio** Ã© o que nos permite gerar conclusÃµes sobre fatos, segundo alguma lÃ³gica prÃ©-estabelecida. Por exemplo, geocientistas sÃ£o capazes de imaginar sistemas deposicionais na subsuperfÃ­cie a quilÃ´metros de profundidade utilizando regras de probabilidade em cima de conhecimento prÃ©-estabelecido na literatura. [Hoffimann et al 2021. Probabilistic Knowledge-based Characterization of Conceptual Geological Models](https://www.sciencedirect.com/science/article/pii/S2590197421000033).
"""

# â•”â•â•¡ 8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
html"""

<p align="center">

    <img src="https://ars.els-cdn.com/content/image/1-s2.0-S2590197421000033-gr1.jpg">

</p>

<p align="center">

    <b>Figura 1</b>: Modelo geolÃ³gico conceitual e possÃ­veis cenÃ¡rios geolÃ³gicos para o sistema deposicional: Braided Rivers, Fluvial Delta, Continental Slope, Inner Shelf.

</p>

"""

# â•”â•â•¡ 301d2074-a2d7-44dc-aeb6-29e69ca5348f
md"""
> **Nota:**
> MÃ©todos de raciocÃ­nio funcionam bem em problemas onde hÃ¡ um enorme acervo de conhecimento. SÃ£o Ã³timos quando (1) poucos dados estÃ£o disponÃ­veis sobre um determinado objeto de estudo, e (2) a literatura Ã© irrefutÃ¡vel.
"""

# â•”â•â•¡ a0b00451-7418-4d60-812f-5c2a9b32cd4d
md"""
A habilidade de **aprendizado**, por outro lado, Ã© o que nos permite **gerar novas regras** baseadas em experiÃªncias presentes. Ã‰ com essa habilidade que evoluimos o nosso entendimento de mundo e criamos novas conexÃµes sobre o ambiente em que operamos.

De forma mais precisa, podemos definir aprendizado em termos de experiÃªncia $E$, tarefa $T$ a ser executada e medida de performance $P$ nessa tarefa. Adotaremos a definiÃ§Ã£o do [Mitchell 1997](http://www.cs.cmu.edu/~tom/mlbook.html):

**DefiniÃ§Ã£o (Aprendizado).** *Dizemos que um agente (e.g. programa de computador) aprende com a experiÃªncia $E$ em relacÃ£o Ã  tarefa $T$ e Ã  medida de performance $P$ se a performance, medida por $P$, melhora com a experiÃªncia $E$.*

Por exemplo, um programa de computador pode aprender a jogar xadrez jogando partidas contra si mesmo. A medida de performance pode ser o nÃºmero de partidas ganhas em um sÃ©rie de 10 partidas, e nesse caso cada Ã© uma experiÃªncia nova adquirida.

Aqui estamos interessados no **aprendizado estatÃ­stico** que consiste de aprender novas regras utilizando grandes bases de dados como furos de sondagem, dados oriundos da geometalurgia, e imagens de satÃ©lite. Em particular, estamos interessados na aplicacÃ£o dessa teoria por meio de programas de computador, conhecida como **aprendizado de mÃ¡quina** (em inglÃªs "machine learning" ou "ML").

A teoria de aprendizado estatÃ­stico estÃ¡ por trÃ¡s de diversas tecnologias atuais, especialmente o **aprendizado estatÃ­stico supervisionado** que consiste em aprender uma funÃ§Ã£o *desconhecida* $f\colon x \mapsto y$ por meio de vÃ¡rios exemplos $\left\{(x_1,y_1), (x_2,y_2),\ldots,(x_n,y_n)\right\}$ de entrada e saÃ­da da funÃ§Ã£o:
"""

# â•”â•â•¡ 29cf81d4-996e-4283-8d72-63d3ed1f55a7
md"""
T: $(@bind T Slider(0.1:0.1:1, default=0.3, show_value=true))

n: $(@bind n Slider(100:100:500, show_value=true))
"""

# â•”â•â•¡ f4ad710d-f2a0-4110-8e6f-d76f181881ae
f(x) = sin(x / T)

# â•”â•â•¡ fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
begin
	xs = rand(Normal(), n)
	ys = f.(xs) .+ rand(Normal(0,0.1), n)
	
	plot(f, -1, 1, color = :green, label = "f(x)",
		 xlims = (-1, 1), ylims = (-1, 1),
		 xlabel = "x", ylabel = "y",
	     title = "Como aprender f(x)?")
	scatter!([(x, -1) for x in xs], label = "xâ‚, xâ‚‚, ..., xâ‚™",
	         marker = (:spike, 10, :black))
	scatter!(collect(zip(xs, ys)), label = "yâ‚, yâ‚‚, ..., yâ‚™",
	         marker = (:circle, 3, :black))
end

# â•”â•â•¡ 6f400014-4f12-42ec-8ee8-db181d82f656
md"""
Quanto mais complexa Ã© a funÃ§Ã£o $f$, mais exemplos sÃ£o necessÃ¡rios para aprendÃª-la segundo alguma medida de performance (e.g. erro quadrÃ¡tico). Por exemplo, se o perÃ­odo de oscilaÃ§Ã£o $T / 2\pi$ da funÃ§Ã£o for baixo, mais densa terÃ¡ que ser a amostragem do eixo $x$ para um aprendizado bem sucedido.

Observamos que:

- O eixo $x$ no aprendizado clÃ¡ssico representa uma **propriedade ou caracterÃ­stica** do exemplo. Por exemplo, o mÃ³dulo de Young ou o teor de um certo minÃ©rio numa amostra.
- O eixo $y$ representa uma **propriedade que se quer prever**, e que estÃ¡ relacionada de alguma forma com a propriedade $x$.
"""

# â•”â•â•¡ a280a283-59c3-4728-9110-b91d5ea63568
md"""
> **Nota:**
> MÃ©todos de aprendizado estatÃ­stico funcionam bem em problemas onde hÃ¡ uma grande quantidade de dados (os exemplos), preferencialmente anotados por especialistas.
"""

# â•”â•â•¡ bfdbec36-069d-422d-8f88-fd97f8d85455
md"""
#### Aprendizado geoestatÃ­stico

A **teoria de aprendizado clÃ¡ssica** utilizada no desenvolvimento de vÃ¡rios mÃ©todos de aprendizado de mÃ¡quina **nÃ£o Ã© apropriada para lidar com dados geoespaciais**, principalmente porque a maior parte da literatura assume que:

1. A distribuiÃ§Ã£o das propriedades dos exemplos Ã© fixa.
2. Os exemplos  sÃ£o independentes e identicamente distribuÃ­dos (I.I.D.).
3. Os exemplos tem um suporte amostral (ou volume fÃ­sico) comum.

Recentemente, nÃ³s formalizamos o problema de **aprendizado geoestatÃ­stico** (em inglÃªs "geostatistical learning" ou "GL") com o intuito de resolver grandes desafios de aprendizado de mÃ¡quina com dados geoespaciais. [Hoffimann et al 2021. Geostatistical Learning: Challenges and Opportunities](https://arxiv.org/abs/2102.08791).

Para ilustrar esses desafios, vamos considerar um conjunto de dados de poÃ§os de petrÃ³leo que construÃ­mos de fontes pÃºblicas da Nova ZelÃ¢ndia ([Carvalho et al. 2020](https://zenodo.org/record/3832955#.YHmR9EOYU3w)):
"""

# â•”â•â•¡ b6b9f6db-5d69-496b-9862-bf7d6add901b
table = CSV.File("data/taranaki/logs.csv") |> DataFrame

# â•”â•â•¡ 2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
md"""
e uma tarefa de aprendizado que consiste em prever o tipo de formaÃ§Ã£o da rocha ($y$ = `FORMATION`) em poÃ§os `OFFSHORE` como funÃ§Ã£o de perfis (ou "logs") eletromagnÃ©ticos ($x$ = (`GR`, `SP`, ...)) e com base em anotaÃ§Ãµes $y_i = f(x_i)$ feitas por especialistas em poÃ§os `ONSHORE` de mais fÃ¡cil acesso.
"""

# â•”â•â•¡ c2fbca00-a248-4f9e-9754-08fd47225bed
md"""
##### FalsificaÃ§Ã£o da hipÃ³tese 1

Por simplicidade, eliminaremos as linhas da tabela com dados faltantes para os logs `GR`, `SP`, `DENS`, `NEUT` e `DTC`, e manteremos apenas as linhas com formaÃ§Ãµes `Urenui` e `Manganui`:
"""

# â•”â•â•¡ b106e967-13c3-483d-bc53-9772c25947be
begin
	# Dados utilizados
	LOGS  = [:GR,:SP,:DENS,:NEUT,:DTC]
	CATEG = [:FORMATION, :ONSHORE]
	COORD = [:X, :Y, :Z]
	FORMS = ["Urenui", "Manganui"]
	
	# OperaÃ§Ãµes de limpeza dos dados
	f1(table) = select(table, [LOGS; CATEG; COORD])
	f2(table) = dropmissing(table)
	f3(table) = filter(row -> row.FORMATION âˆˆ FORMS, table)
	
	# Sequenciamento de operaÃ§Ãµes
	samples = table |> f1 |> f2 |> f3
end

# â•”â•â•¡ 9e6849d8-4c4b-4b18-a12e-734b45f9e41f
md"""
Para facilitar a interpretaÃ§Ã£o dos dados e o posterior treinamento de modelos de aprendizado, nÃ³s normalizaremos os logs para que tenham mÃ©dia zero e desvio padrÃ£o unitÃ¡rio:
"""

# â•”â•â•¡ 48a4fdfb-07d8-4ce9-a489-5f9611ed4c5b
for LOG in LOGS
	# Seleciona coluna com o log
	x = samples[!, LOG]
	
	# Calcula mÃ©dia e desvio padrÃ£o
	Î¼ = mean(x)
	Ïƒ = std(x, mean = Î¼)
	
	# Normaliza coluna
	samples[!, LOG] = (x .- Î¼) ./ Ïƒ
end

# â•”â•â•¡ e912de0f-cab2-4e11-b0bd-6a9603a9e966
describe(samples)

# â•”â•â•¡ ce132078-cfd3-4455-98b4-3297b1be405f
md"""
Como a tarefa de aprendizado que definimos consiste em prever a formaÃ§Ã£o em poÃ§os `OFFSHORE` baseado em anotaÃ§Ãµes em poÃ§os `ONSHORE`, nÃ³s visualizaremos os dados agrupados dessa forma. Em particular, nÃ³s queremos investigar a distribuiÃ§Ã£o bivariada entre o logs $(@bind X1 Select(string.(LOGS))) e $(@bind X2 Select(string.(LOGS), default="SP")) nesse agrupamento:
"""

# â•”â•â•¡ 4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
begin
	# Agrupamento em pocos onshore and offshore
	G1, G2 = DataFrames.groupby(samples, :ONSHORE)
	
	T1 = G1.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	T2 = G2.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	
	p1 = scatter(G1[!,X1], G1[!,X2], marker = (:gray, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T1)
	p2 = scatter(G2[!,X1], G2[!,X2], marker = (:purple, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T2)
	
	plot(p1, p2, link = :both, aspect_ratio = :equal, size = (700, 400))
end

# â•”â•â•¡ 4eadc228-7905-4328-ab01-f21339dd40aa
md"""
Da visualizaÃ§Ã£o concluimos que a hipÃ³tese (1) da teoria clÃ¡ssica nÃ£o Ã© vÃ¡lida neste caso. Isto Ã©, a **distribuiÃ§Ã£o das propriedades dos exemplos varia drasticamente** de um domÃ­nio geolÃ³gico para outro, mesmo quando consideramos um subconjunto pequeno dos dados para duas formaÃ§Ãµes localizadas em uma Ãºnica bacia.
"""

# â•”â•â•¡ 3855a6d5-7b8a-487b-abad-288f9fc0152d
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 2

Vejamos agora a hipÃ³tese (2) da teoria clÃ¡ssica que assume que exemplos utilizados no treinamento de um modelo de aprendizado sÃ£o amostrados de forma independente.

Para avaliarmos essa hipÃ³tese, utilizaremos a anÃ¡lise variogrÃ¡fica. O GeoStats.jl possui estimadores de variogramas de alta performance que conseguem lidar com **centenas de milhares** de amostras em poucos segundos. [Hoffimann & Zadrozny. 2019. Efficient variography with partition variograms.](https://www.sciencedirect.com/science/article/pii/S0098300419302936).

Primeiro nÃ³s georreferenciamos as amostras em um dado geoespacial utilizando a funÃ§Ã£o `georef` e agregamos as amostras que possuem coordenadas repetidas utilizando a funÃ§Ã£o `uniquecoords`:
"""

# â•”â•â•¡ 3a425474-8710-42f7-83b4-6db8b6fc14b9
ğ’® = georef(samples, (:X, :Y, :Z)) |> uniquecoords

# â•”â•â•¡ c10c7845-61ec-4275-b9a0-4934a7848e9b
md"""
Em seguida calculamos o variograma direcional (vertical) ao longo da direÃ§Ã£o dos poÃ§os:
"""

# â•”â•â•¡ d70ac330-0aae-4fae-91a2-159f1c1bc11f
Î³ = DirectionalVariogram((0.,0.,1.), ğ’®, :GR, maxlag = 100., nlags = 50, dtol = 10.)

# â•”â•â•¡ 44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
plot(Î³)

# â•”â•â•¡ 32f8bc26-97e4-4cfa-b064-eebe0403accb
md"""
O comprimento de correlaÃ§Ã£o ou "range" positivo do variograma indica a dependÃªncia espacial das amostras, e pode ser estimado por mÃ­nimos quadrados ponderados:
"""

# â•”â•â•¡ dcc82e49-af10-4f9c-927d-1cf039a6185a
Î³â‚œ = fit(Variogram, Î³, h -> exp(-h/20))

# â•”â•â•¡ 86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
range(Î³â‚œ)

# â•”â•â•¡ 6d1b48f9-c7c6-461d-9908-f2a36de2694f
plot(Î³); plot!(Î³â‚œ, 0, 100)

# â•”â•â•¡ 4c76d345-1d77-4f7f-9fbe-2d4707d70b29
md"""
A partir da anÃ¡lise variogrÃ¡fica, concluimos que a hipÃ³tese (2) tambÃ©m nÃ£o Ã© valida neste caso. As amostras sÃ£o adjacentes no espaÃ§o fÃ­sico, e estÃ£o mais prÃ³ximas entre si do que o comprimento de correlaÃ§Ã£o do processo. Ou seja, as **amostras estÃ£o associadas geoespacialmente**.
"""

# â•”â•â•¡ 06e19a21-5a4e-48c0-9030-9c6c43a3afdb
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 3

A hipÃ³tese (3) nÃ£o Ã© valida, pois como discutimos no primeiro dia do minicurso, amostras geofÃ­sicas geralmente tem um suporte (ou volume fÃ­sico) variÃ¡vel. Neste caso, **o espaÃ§amento das amostras ao longo dos poÃ§os nÃ£o Ã© constante**.
"""

# â•”â•â•¡ e3c46f60-b32e-4911-971f-230c87507f37
md"""
#### Resumo

- A **anÃ¡lise bivariada** indicou que as **distribuiÃ§Ãµes das propriedades** em poÃ§os `ONSHORE` e `OFFSHORE` **sÃ£o distintas**. Portanto, nÃ£o Ã© aconselhÃ¡vel treinar um modelo de aprendizado com anotaÃ§Ãµes em poÃ§os `ONSHORE` e aplicÃ¡-lo diretamente a poÃ§os `OFFSHORE`, e vice versa.

- A **anÃ¡lise variogrÃ¡fica** indicou a **existÃªncia de correlaÃ§Ã£o linear** ao longo dos poÃ§os. Isso significa que modelos de aprendizado clÃ¡ssicos desenvolvidos assumindo independÃªncia de exemplos podem apresentar, e geralmente apresentam, deterioraÃ§Ã£o de performance em aplicaÃ§Ãµes prÃ¡ticas em geociÃªncias.

Precisamos de uma nova definiÃ§Ã£o de aprendizado com dados geoespaciais, que chamaremos de **aprendizado geoestatÃ­stico** ou GL:

**DefiniÃ§Ã£o (GL).** *Dado um domÃ­nio geoespacial de origem $D_s$ (ou "source") e uma tarefa de aprendizado $T_s$, e um domÃ­nio de destino $D_t$ (ou "target") e uma tarefa de aprendizado $T_t$. O aprendizado geoestatÃ­stico consiste em aprender a tarefa $T_t$ no domÃ­nio $D_t$ utilizando o conhecimento adquirido no aprendizado da tarefa $T_s$ no domÃ­nio $D_s$. Assumindo que as propriedades em $D_s$ e $D_t$ sÃ£o uma Ãºnica realizaÃ§Ã£o dos processos envolvidos.*
"""

# â•”â•â•¡ 0e168bfe-902b-4732-8ecb-a9a75b330bbb
md"""
### Elementos do aprendizado geoestatÃ­stico
"""

# â•”â•â•¡ fbd3a1ec-214f-450f-9c2e-547df22157d3


# â•”â•â•¡ Cell order:
# â•Ÿâ”€32f6d41e-3248-4549-9546-53b34d5aa7c6
# â•Ÿâ”€762a6e04-fcb7-4713-859d-fdbfe8ead1bc
# â•Ÿâ”€32429926-f6c3-44b8-b012-d2c67cad0b6d
# â•Ÿâ”€3c79e7aa-b316-4c4b-b44e-e73312085c20
# â•Ÿâ”€4a3fb559-73dd-41e0-8a11-993e5bf286bf
# â•Ÿâ”€f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
# â•Ÿâ”€1856e01b-2d55-448d-8bdf-e59825934193
# â•Ÿâ”€8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
# â•Ÿâ”€301d2074-a2d7-44dc-aeb6-29e69ca5348f
# â•Ÿâ”€a0b00451-7418-4d60-812f-5c2a9b32cd4d
# â• â•f4ad710d-f2a0-4110-8e6f-d76f181881ae
# â•Ÿâ”€29cf81d4-996e-4283-8d72-63d3ed1f55a7
# â•Ÿâ”€fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
# â•Ÿâ”€6f400014-4f12-42ec-8ee8-db181d82f656
# â•Ÿâ”€a280a283-59c3-4728-9110-b91d5ea63568
# â•Ÿâ”€bfdbec36-069d-422d-8f88-fd97f8d85455
# â• â•b6b9f6db-5d69-496b-9862-bf7d6add901b
# â•Ÿâ”€2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
# â•Ÿâ”€c2fbca00-a248-4f9e-9754-08fd47225bed
# â• â•b106e967-13c3-483d-bc53-9772c25947be
# â•Ÿâ”€9e6849d8-4c4b-4b18-a12e-734b45f9e41f
# â• â•48a4fdfb-07d8-4ce9-a489-5f9611ed4c5b
# â• â•e912de0f-cab2-4e11-b0bd-6a9603a9e966
# â•Ÿâ”€ce132078-cfd3-4455-98b4-3297b1be405f
# â•Ÿâ”€4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
# â•Ÿâ”€4eadc228-7905-4328-ab01-f21339dd40aa
# â•Ÿâ”€3855a6d5-7b8a-487b-abad-288f9fc0152d
# â• â•3a425474-8710-42f7-83b4-6db8b6fc14b9
# â•Ÿâ”€c10c7845-61ec-4275-b9a0-4934a7848e9b
# â• â•d70ac330-0aae-4fae-91a2-159f1c1bc11f
# â• â•44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
# â•Ÿâ”€32f8bc26-97e4-4cfa-b064-eebe0403accb
# â• â•dcc82e49-af10-4f9c-927d-1cf039a6185a
# â• â•86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
# â• â•6d1b48f9-c7c6-461d-9908-f2a36de2694f
# â•Ÿâ”€4c76d345-1d77-4f7f-9fbe-2d4707d70b29
# â•Ÿâ”€06e19a21-5a4e-48c0-9030-9c6c43a3afdb
# â•Ÿâ”€e3c46f60-b32e-4911-971f-230c87507f37
# â•Ÿâ”€0e168bfe-902b-4732-8ecb-a9a75b330bbb
# â• â•fbd3a1ec-214f-450f-9c2e-547df22157d3
