### A Pluto.jl notebook ###
# v0.14.2

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : missing
        el
    end
end

# â•”â•â•¡ 32f6d41e-3248-4549-9546-53b34d5aa7c6
begin
	# instantiate environment
	using Pkg; Pkg.activate(@__DIR__); Pkg.instantiate()

	# load packages used in this notebook
	using GeoStats, MLJ
	using CSV, DataFrames
	using Distributions
	using PlutoUI
	using Plots
	using StatsPlots

	# default plot settings
	gr(format=:png)
end;

# â•”â•â•¡ 762a6e04-fcb7-4713-859d-fdbfe8ead1bc
html"""
<p style="background-color:lightgrey" xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">GeoStats.jl at CBMina</span> by <span property="cc:attributionName">JÃºlio Hoffimann & Franco Naghetini</span> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>
"""

# â•”â•â•¡ 32429926-f6c3-44b8-b012-d2c67cad0b6d
md"""
![geostats-logo](https://github.com/JuliaEarth/GeoStats.jl/blob/master/docs/src/assets/logo-text.svg?raw=true)

# GeostatÃ­stica moderna

Instrutores: [JÃºlio Hoffimann](https://juliohm.github.io) & [Franco Naghetini](https://github.com/fnaghetini)
"""

# â•”â•â•¡ 3c79e7aa-b316-4c4b-b44e-e73312085c20
md"""
## Aprendizado geoestatÃ­stico

Neste mÃ³dulo aprenderemos sobre esta nova Ã¡rea denominada **aprendizado geoestatÃ­stico** ([Hoffimann et al 2021](https://arxiv.org/abs/2102.08791)). Introduziremos os elementos do problema de aprendizado com **dados geoespaciais**, e veremos como a biblioteca [GeoStats.jl](https://github.com/JuliaEarth/GeoStats.jl) estÃ¡ na vanguarda desta tecnologia.

Existem questÃµes teÃ³ricas muito interessantes que nÃ£o cobriremos neste minicurso, e que estÃ£o sendo desenvolvidas ativamente no projeto. Nos concentraremos aqui em **exemplos prÃ¡ticos** para que vocÃª possa adaptar este notebook aos seus prÃ³prios desafios na mineraÃ§Ã£o. Para mais detalhes teÃ³ricos, assista o vÃ­deo abaixo:
"""

# â•”â•â•¡ 4a3fb559-73dd-41e0-8a11-993e5bf286bf
html"""
<iframe width="560" height="315" src="https://www.youtube.com/embed/6S_9GLMv3xI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
"""

# â•”â•â•¡ f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
md"""
Ao final deste mÃ³dulo vocÃª serÃ¡ capaz de:

- Identificar os **elementos do aprendizado geoestatÃ­stico**
- Definir de forma clara **problemas de aprendizado na sua Ã¡rea**
- Resolver o problema com **modelos geoespaciais do GeoStats.jl**

### Agenda

1. O que Ã© aprendizado de mÃ¡quina?
2. A nova Ã¡rea de **aprendizado geoestatÃ­stico**
3. Os elementos do aprendizado geoestatÃ­stico
4. SoluÃ§Ã£o do problema (exemplo *Nova ZelÃ¢ndia*)
5. MÃ©todos de validaÃ§Ã£o (seleÃ§Ã£o de modelos)
"""

# â•”â•â•¡ 1856e01b-2d55-448d-8bdf-e59825934193
md"""
### 1. O que Ã© o aprendizado de mÃ¡quina?

Antes de podermos entender o problema de aprendizado **geo**estatÃ­stico, isto Ã©, o problema de aprendizado com dados **geoespacias**, precisamos entender o problema genÃ©rico de **aprendizado de mÃ¡quina** introduzido na ciÃªncia da computaÃ§Ã£o na Ã¡rea de **inteligÃªncia artificial**.

Nessa Ã¡rea, buscam-se criar tecnologias capazes de "imitar" a inteligÃªncia humana. Ao invÃ©s de tentarmos definir inteligÃªncia, vamos nos concentrar em duas habilidades que nÃ³s humanos exercermos todo dia:

- A habilidade de **raciocinar sobre fatos**
- A habilidade **aprender com experiÃªncia**

#### RaciocÃ­nio

A habilidade de **raciocÃ­nio** Ã© o que nos permite gerar conclusÃµes sobre fatos, segundo alguma lÃ³gica prÃ©-estabelecida. Essa habilidade pode ser entendida informalmente como um sistema **dedutivo** da forma:

$\text{premissa}_1 + \text{premissa}_2 + \cdots + \text{premissa}_n \longrightarrow \text{conclusÃ£o}$

onde um conjunto de **premissas** sobre o funcionamento do mundo leva a uma **conclusÃ£o** lÃ³gica. Como exemplo, podemos considerar a habilidade de um geÃ³logo de deduzir condiÃ§Ãµes marÃ­timas ao ver o fÃ³ssil da Figura 2. O raciocÃ­nio se dÃ¡ da seguinte forma:

- *Premissa 1:* Trilobitas sÃ£o seres marinhos
- *Premissa 2:* FÃ³ssil de trilobita encontrado na regiÃ£o
- *ConclusÃ£o:* RegiÃ£o foi mar num passado distante
"""

# â•”â•â•¡ 615e4ed2-f77f-4f38-a6c1-7f0c0f985d49
html"""

<p align="center">

    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQLZzO7ZIjwJzgTPHk6EootRI5usLZCcuDJ-f0Vdz6aYq2rPpNFpaFM8FBPgny42fGfYQQ&usqp=CAU">

</p>

<p align="center">

    <b>Figura 1</b>: FÃ³ssil de trilobita, um antrÃ³pode do paleozÃ³ico de ambientes marinhos.

</p>

"""

# â•”â•â•¡ b89139a7-57da-4d9d-a791-c06edd5ab99d
md"""
Devemos observar que:

- Sistemas de raciocÃ­nio determinÃ­sticos como o exemplo acima tendem a nÃ£o ser robustos em Ã¡reas da ciÃªncia que apresentam alta complexidade e interaÃ§Ã£o entre as entidades envolvidas no raciocÃ­nio, especialmente quando esses sistemas sÃ£o construÃ­dos por [seres humanos e seus vÃ¡rios traÃ§os de irracionalidade](https://en.wikipedia.org/wiki/Predictably_Irrational).

- Sistemas de raciocÃ­nio probabilÃ­sticos, isto Ã©, sistemas que utilizam de teorias de probabilidade para representar incertezas no raciocÃ­nio, tem sido mais bem sucedidos na indÃºstria. Um exemplo deste tipo de sistema estÃ¡ descrito em [Hoffimann et al 2021. Probabilistic Knowledge-based Characterization of Conceptual Geological Models](https://www.sciencedirect.com/science/article/pii/S2590197421000033), onde um modelo conhecido como rede Bayesiana Ã© utilizado para auxiliar geocientistas na identificaÃ§Ã£o de cenÃ¡rios geolÃ³gicos de um sistema petrolÃ­fero (Figura 2).
"""

# â•”â•â•¡ 8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
html"""

<p align="center">

    <img src="https://ars.els-cdn.com/content/image/1-s2.0-S2590197421000033-gr1.jpg">

</p>

<p align="center">

    <b>Figura 2</b>: Modelo geolÃ³gico conceitual e possÃ­veis cenÃ¡rios geolÃ³gicos para o sistema deposicional: Braided Rivers, Fluvial Delta, Continental Slope, Inner Shelf.

</p>

"""

# â•”â•â•¡ 301d2074-a2d7-44dc-aeb6-29e69ca5348f
md"""
> **Nota:** MÃ©todos de raciocÃ­nio funcionam bem em problemas onde hÃ¡ um enorme acervo de conhecimento. SÃ£o Ã³timos quando (1) poucos dados estÃ£o disponÃ­veis sobre um determinado objeto de estudo, e (2) a literatura Ã© irrefutÃ¡vel.
"""

# â•”â•â•¡ a0b00451-7418-4d60-812f-5c2a9b32cd4d
md"""
#### Aprendizado

A habilidade de **aprendizado**, por outro lado, Ã© o que nos permite **gerar novas regras** sobre o ambiente em que operamos baseado em novas experiÃªncias vividas. Ã‰ com essa habilidade que evoluimos o nosso entendimento de mundo.

De forma mais precisa, podemos definir aprendizado em termos de experiÃªncia $\mathcal{E}$, tarefa $\mathcal{T}$ a ser executada e medida de performance $\mathcal{P}$ nessa tarefa. Adotaremos a definiÃ§Ã£o do [Mitchell 1997](http://www.cs.cmu.edu/~tom/mlbook.html):

**DefiniÃ§Ã£o (Aprendizado).** *Dizemos que um agente (e.g. programa de computador) aprende com a experiÃªncia $\mathcal{E}$ em relacÃ£o Ã  tarefa $\mathcal{T}$ e Ã  medida de performance $\mathcal{P}$ se a performance, medida por $\mathcal{P}$, melhora com a experiÃªncia $\mathcal{E}$.*

Por exemplo, um programa de computador pode aprender a jogar xadrez jogando partidas contra si mesmo. A medida de performance pode ser o nÃºmero de partidas ganhas em um sÃ©rie de 10 partidas, e nesse caso cada partida Ã© uma experiÃªncia nova adquirida.

Aqui estamos interessados no **aprendizado estatÃ­stico** que consiste de aprender novas regras utilizando grandes bases de dados como furos de sondagem, dados oriundos da geometalurgia, e imagens de satÃ©lite. Em particular, estamos interessados na aplicacÃ£o dessa teoria por meio de programas de computador, conhecida como **aprendizado de mÃ¡quina** (em inglÃªs "machine learning" ou "ML").

A teoria de aprendizado estatÃ­stico estÃ¡ por trÃ¡s de diversas tecnologias atuais, especialmente o **aprendizado estatÃ­stico supervisionado** que consiste em aprender uma funÃ§Ã£o *desconhecida* $f\colon x \mapsto y$ por meio de vÃ¡rios exemplos $\left\{(x_1,y_1), (x_2,y_2),\ldots,(x_n,y_n)\right\}$ de entrada e saÃ­da da funÃ§Ã£o:
"""

# â•”â•â•¡ 29cf81d4-996e-4283-8d72-63d3ed1f55a7
md"""
T: $(@bind T Slider(0.1:0.1:1, default=0.3, show_value=true))

n: $(@bind n Slider(100:100:500, show_value=true))
"""

# â•”â•â•¡ f4ad710d-f2a0-4110-8e6f-d76f181881ae
f(x) = sin(x / T)

# â•”â•â•¡ fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
begin
	xs = rand(Normal(), n)
	ys = f.(xs) .+ rand(Normal(0,0.1), n)
	
	plot(f, -1, 1, color = :green, label = "f(x)",
		 xlims = (-1, 1), ylims = (-1, 1),
		 xlabel = "x", ylabel = "y",
	     title = "Como aprender f(x)?")
	scatter!([(x, -1) for x in xs], label = "xâ‚, xâ‚‚, ..., xâ‚™",
	         marker = (:spike, 10, :black))
	scatter!(collect(zip(xs, ys)), label = "yâ‚, yâ‚‚, ..., yâ‚™",
	         marker = (:circle, 3, :black))
end

# â•”â•â•¡ 6f400014-4f12-42ec-8ee8-db181d82f656
md"""
Quanto mais complexa Ã© a funÃ§Ã£o $f$, mais exemplos sÃ£o necessÃ¡rios para aprendÃª-la segundo alguma medida de performance (e.g. erro quadrÃ¡tico). Por exemplo, se o perÃ­odo de oscilaÃ§Ã£o $T / 2\pi$ da funÃ§Ã£o acima for baixo, mais densa terÃ¡ que ser a amostragem do eixo $x$ para um aprendizado bem sucedido.

Observamos que:

- O eixo $x$ no aprendizado clÃ¡ssico representa uma **propriedade ou caracterÃ­stica** do exemplo. Por exemplo, o mÃ³dulo de Young ou o teor de um certo minÃ©rio numa amostra.
- O eixo $y$ representa uma **propriedade que se quer prever**, e que estÃ¡ relacionada de alguma forma com a propriedade $x$.
"""

# â•”â•â•¡ a280a283-59c3-4728-9110-b91d5ea63568
md"""
> **Nota:** MÃ©todos de aprendizado estatÃ­stico funcionam bem em problemas onde hÃ¡ uma grande quantidade de dados (os exemplos), preferencialmente anotados por especialistas.
"""

# â•”â•â•¡ bfdbec36-069d-422d-8f88-fd97f8d85455
md"""
### 2. Aprendizado geoestatÃ­stico

A **teoria de aprendizado clÃ¡ssica** utilizada no desenvolvimento de vÃ¡rios mÃ©todos de aprendizado de mÃ¡quina **nÃ£o Ã© apropriada para lidar com dados geoespaciais**, principalmente porque a maior parte da literatura assume que:

1. A distribuiÃ§Ã£o das propriedades dos exemplos Ã© fixa.
2. Os exemplos  sÃ£o independentes e identicamente distribuÃ­dos (I.I.D.).
3. Os exemplos tem um suporte amostral (ou volume fÃ­sico) comum.

Recentemente, nÃ³s formalizamos o problema de **aprendizado geoestatÃ­stico** (em inglÃªs "geostatistical learning" ou "GL") com o intuito de resolver grandes desafios de aprendizado de mÃ¡quina com dados geoespaciais. [Hoffimann et al 2021. Geostatistical Learning: Challenges and Opportunities](https://arxiv.org/abs/2102.08791).

Para ilustrar esses desafios, vamos considerar um conjunto de dados de poÃ§os de petrÃ³leo que construÃ­mos de fontes pÃºblicas da Nova ZelÃ¢ndia ([Carvalho et al. 2020](https://zenodo.org/record/3832955#.YHmR9EOYU3w)):
"""

# â•”â•â•¡ b6b9f6db-5d69-496b-9862-bf7d6add901b
table = CSV.File("data/taranaki/logs.csv") |> DataFrame

# â•”â•â•¡ 2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
md"""
e uma tarefa de aprendizado que consiste em prever o tipo de formaÃ§Ã£o da rocha ($y$ = `FORMATION`) em poÃ§os `OFFSHORE` como funÃ§Ã£o de perfis (ou "logs") eletromagnÃ©ticos ($x$ = (`GR`, `SP`, ...)) e com base em anotaÃ§Ãµes $y_i = f(x_i)$ feitas por especialistas em poÃ§os `ONSHORE` de mais fÃ¡cil acesso.
"""

# â•”â•â•¡ c2fbca00-a248-4f9e-9754-08fd47225bed
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 1

Por simplicidade, eliminaremos as linhas da tabela com dados faltantes para os logs `GR`, `SP`, `DENS`, `NEUT` e `DTC`, e manteremos apenas as linhas com formaÃ§Ãµes `Manganui` e `Urenui`.

Para facilitar a interpretaÃ§Ã£o dos dados e o posterior treinamento de modelos de aprendizado, nÃ³s normalizaremos os logs para que tenham mÃ©dia zero e desvio padrÃ£o unitÃ¡rio.
"""

# â•”â•â•¡ b106e967-13c3-483d-bc53-9772c25947be
begin
	# Dados utilizados no experimento
	LOGS  = [:GR,:SP,:DENS,:NEUT,:DTC]
	CATEG = [:FORMATION, :ONSHORE]
	COORD = [:X, :Y, :Z]
	FORMS = ["Manganui", "Urenui"]
	
	# OperaÃ§Ãµes de prÃ©-processamento
	f1(table) = select(table, [LOGS; CATEG; COORD])
	
	f2(table) = dropmissing(table)
	
	f3(table) = filter(row -> row.FORMATION âˆˆ FORMS, table)
	
	function f4(table)
		result = copy(table)
		for LOG in LOGS
			x = table[!, LOG]
			
			Î¼ = mean(x)
			Ïƒ = std(x, mean = Î¼)
	
			result[!, LOG] = (x .- Î¼) ./ Ïƒ
		end
		result
	end
	
	# ExecuÃ§Ã£o da sequÃªncia de operaÃ§Ãµes
	samples = table |> f1 |> f2 |> f3 |> f4
end

# â•”â•â•¡ e912de0f-cab2-4e11-b0bd-6a9603a9e966
describe(samples)

# â•”â•â•¡ ce132078-cfd3-4455-98b4-3297b1be405f
md"""
Como a tarefa de aprendizado que definimos consiste em prever a formaÃ§Ã£o em poÃ§os `OFFSHORE` baseado em anotaÃ§Ãµes em poÃ§os `ONSHORE`, nÃ³s visualizaremos os dados agrupados dessa forma. Em particular, nÃ³s queremos investigar a **distribuiÃ§Ã£o bivariada** entre o logs $(@bind X1 Select(string.(LOGS))) e $(@bind X2 Select(string.(LOGS), default="SP")) nesse agrupamento:
"""

# â•”â•â•¡ 4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
begin
	# Agrupamento em pocos onshore and offshore
	G1, G2 = DataFrames.groupby(samples, :ONSHORE)
	
	T1 = G1.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	T2 = G2.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	
	p1 = scatter(G1[!,X1], G1[!,X2], marker = (:gray, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T1)
	p2 = scatter(G2[!,X1], G2[!,X2], marker = (:purple, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T2)
	
	plot(p1, p2, link = :both, aspect_ratio = :equal, size = (700, 400))
end

# â•”â•â•¡ 4eadc228-7905-4328-ab01-f21339dd40aa
md"""
Da visualizaÃ§Ã£o concluimos que a hipÃ³tese (1) da teoria clÃ¡ssica nÃ£o Ã© vÃ¡lida neste caso. Isto Ã©, a **distribuiÃ§Ã£o das propriedades dos exemplos varia drasticamente** de um domÃ­nio geolÃ³gico para outro, mesmo quando consideramos um subconjunto pequeno dos dados para duas formaÃ§Ãµes localizadas em uma Ãºnica bacia.
"""

# â•”â•â•¡ 3855a6d5-7b8a-487b-abad-288f9fc0152d
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 2

Vejamos agora a hipÃ³tese (2) da teoria clÃ¡ssica que assume que exemplos utilizados no treinamento de um modelo de aprendizado sÃ£o amostrados de forma independente no espaÃ§o de propriedades.

Para avaliarmos essa hipÃ³tese, utilizaremos a **anÃ¡lise variogrÃ¡fica**. O GeoStats.jl possui estimadores de variogramas de alta performance que conseguem lidar com **centenas de milhares** de amostras em poucos segundos. [Hoffimann & Zadrozny. 2019. Efficient variography with partition variograms.](https://www.sciencedirect.com/science/article/pii/S0098300419302936).

Para utilizar esses estimadores, nÃ³s precisaremos **georreferenciar a tabela** de amostras em um dado geoespacial do GeoStats.jl que chamamos de `GeoData`. Esse dado se comporta como uma tabela comum, mas adicionalmente armazena informaÃ§Ãµes necessÃ¡rias para anÃ¡lises geoespaciais.

AlÃ©m de georreferenciar as amostras, nÃ³s iremos aproveitar esta etapa de processamento para especificar o **tipo cientÃ­fico** de cada coluna da tabela. Por padrÃ£o esses tipos sÃ£o inferidos pela linguagem como:
"""

# â•”â•â•¡ eb9d3014-65b2-44f7-8d33-445826e6974b
schema(samples)

# â•”â•â•¡ 4b41d46e-ccf0-4232-8ce8-f9520a90efea
md"""
NÃ³s iremos converter os tipos cientÃ­ficos `Textual` e `Count` das colunas `FORMATION` e `ONSHORE` pelo tipo `Multiclass` que representa uma propriedade categÃ³rica.

Por fim, nÃ³s iremos agregar todas as amostras com coordenadas repetidas em uma Ãºnica amostra jÃ¡ que procedimentos de variografia requerem unicidade de coordenadas no conjunto de dados.

Em resumo, nÃ³s utilizaremos:

1. A funÃ§Ã£o `coerce` para especificar o tipo cientÃ­fico das colunas `FORMATION` e `ONSHORE`.
2. A funÃ§Ã£o `georef` para georreferenciar as amostras utilizando as coordenadas `X`, `Y` e `Z`.
3. A funÃ§Ã£o `uniquecoords` para eliminar amostras com coordenadas repetidas.
"""

# â•”â•â•¡ a1c4fc51-1878-4c13-8d01-3642d23ee670
begin
	# OperaÃ§Ãµes de prÃ©-processamento
	g1(table) = coerce(table, :FORMATION => Multiclass, :ONSHORE => Multiclass)
	
	g2(table) = georef(table, (:X, :Y, :Z))
	
	g3(table) = uniquecoords(table)
	
	# ExecuÃ§Ã£o da sequÃªncia de operaÃ§Ãµes
	ğ’® = samples |> g1 |> g2 |> g3 |> GeoData
end

# â•”â•â•¡ c10c7845-61ec-4275-b9a0-4934a7848e9b
md"""
Para avaliar a dependÃªncia das amostras, calculamos o variograma direcional (vertical) ao longo da direÃ§Ã£o dos poÃ§os para qualquer uma das variÃ¡veis:
"""

# â•”â•â•¡ d70ac330-0aae-4fae-91a2-159f1c1bc11f
Î³ = DirectionalVariogram((0.,0.,1.), ğ’®, :GR, maxlag = 100., nlags = 50, dtol = 10.)

# â•”â•â•¡ 44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
plot(Î³)

# â•”â•â•¡ 32f8bc26-97e4-4cfa-b064-eebe0403accb
md"""
O comprimento de correlaÃ§Ã£o ou "range" positivo do variograma indica a dependÃªncia espacial das amostras, e pode ser estimado por mÃ­nimos quadrados ponderados:
"""

# â•”â•â•¡ dcc82e49-af10-4f9c-927d-1cf039a6185a
Î³â‚œ = fit(Variogram, Î³, h -> exp(-h/20))

# â•”â•â•¡ 86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
range(Î³â‚œ)

# â•”â•â•¡ 6d1b48f9-c7c6-461d-9908-f2a36de2694f
plot(Î³); plot!(Î³â‚œ, 0, 100)

# â•”â•â•¡ 4c76d345-1d77-4f7f-9fbe-2d4707d70b29
md"""
A partir da anÃ¡lise variogrÃ¡fica, concluimos que a hipÃ³tese (2) tambÃ©m nÃ£o Ã© valida neste caso. As amostras sÃ£o adjacentes no espaÃ§o fÃ­sico, e estÃ£o mais prÃ³ximas entre si do que o comprimento de correlaÃ§Ã£o do processo. Ou seja, as **amostras estÃ£o associadas geoespacialmente**.
"""

# â•”â•â•¡ 06e19a21-5a4e-48c0-9030-9c6c43a3afdb
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 3

A hipÃ³tese (3) nÃ£o Ã© valida, pois como discutimos no primeiro dia do minicurso, amostras geofÃ­sicas geralmente tem um suporte (ou volume fÃ­sico) variÃ¡vel. Neste caso, **o espaÃ§amento das amostras ao longo dos poÃ§os nÃ£o Ã© constante**.
"""

# â•”â•â•¡ e3c46f60-b32e-4911-971f-230c87507f37
md"""
#### Resumo

- A **anÃ¡lise bivariada** indicou que as **distribuiÃ§Ãµes das propriedades** em poÃ§os `ONSHORE` e `OFFSHORE` **sÃ£o distintas**. Portanto, nÃ£o Ã© aconselhÃ¡vel treinar um modelo de aprendizado com anotaÃ§Ãµes em poÃ§os `ONSHORE` e aplicÃ¡-lo diretamente a poÃ§os `OFFSHORE`, e vice versa.

- A **anÃ¡lise variogrÃ¡fica** indicou a **existÃªncia de correlaÃ§Ã£o linear** ao longo dos poÃ§os. Isso significa que modelos de aprendizado clÃ¡ssicos desenvolvidos assumindo independÃªncia de exemplos podem apresentar, e geralmente apresentam, deterioraÃ§Ã£o de performance em aplicaÃ§Ãµes prÃ¡ticas em geociÃªncias.

Precisamos de uma nova definiÃ§Ã£o de aprendizado com dados geoespaciais, que chamaremos de **aprendizado geoestatÃ­stico** ou GL:

**DefiniÃ§Ã£o (GL).** *Dado um domÃ­nio geoespacial de origem $\mathcal{D}_s$ (ou "source") e uma tarefa de aprendizado $\mathcal{T}_s$, e um domÃ­nio de destino $\mathcal{D}_t$ (ou "target") e uma tarefa de aprendizado $\mathcal{T}_t$. O aprendizado geoestatÃ­stico consiste em aprender a tarefa $\mathcal{T}_t$ no domÃ­nio $\mathcal{D}_t$ utilizando o conhecimento adquirido no aprendizado da tarefa $\mathcal{T}_s$ no domÃ­nio $\mathcal{D}_s$. Assumindo que as propriedades em $\mathcal{D}_s$ e $\mathcal{D}_t$ sÃ£o uma Ãºnica realizaÃ§Ã£o dos processos envolvidos.*
"""

# â•”â•â•¡ 0e168bfe-902b-4732-8ecb-a9a75b330bbb
md"""
### 3. Elementos do aprendizado geoestatÃ­stico

Para esclarecer a definiÃ§Ã£o de GL, continuaremos explorando os dados da Nova ZelÃ¢ndia.

#### DomÃ­nio geoespacial

O primeiro elemento da definiÃ§Ã£o Ã© o **domÃ­nio geoespacial** onde os dados estÃ£o georreferenciados:

- O **domÃ­nio de origem** $\mathcal{D}_s$ representa as trajetÃ³rias dos poÃ§os `ONSHORE`. Nesse domÃ­nio estÃ£o disponÃ­veis os logs, assim como as anotaÃ§Ãµes do tipo de formaÃ§Ã£o feitas por especialistas.
- O **domÃ­nio de destino** $\mathcal{D}_t$ representa as trajetÃ³rias dos poÃ§os `OFFSHORE`. Nesse domÃ­nio estÃ£o disponÃ­veis apenas os logs que serÃ£o utilizados pelo modelo de aprendizao para previsÃ£o do tipo de formaÃ§Ã£o.

Vemos que os nossos dados geoespaciais estÃ£o definidos em um domÃ­nio do tipo `PointSet`:
"""

# â•”â•â•¡ 8ee75575-d2f2-409f-9016-dac048fc6ff6
domain(ğ’®)

# â•”â•â•¡ a21d65cb-d369-4e9b-a1a6-53b06b09dc22
md"""
E que a tabela de valores associada a esse domÃ­nio contÃ©m as seguintes variÃ¡veis:
"""

# â•”â•â•¡ cb8d9a31-d415-45b7-a743-15c715dfd2a5
values(ğ’®) |> DataFrame

# â•”â•â•¡ 8712e1ec-0b84-4fc4-a44e-6f5a91180b8b
md"""
Queremos particionar os dados em poÃ§os `ONSHORE` e `OFFSHORE` de acordo com a informaÃ§Ã£o jÃ¡ presente na tabela de valores. Utilizaremos a funÃ§Ã£o `groupby` do GeoStats.jl para **particionar os dados preservando as informaÃ§Ãµes geoespaciais**. O resultado da partiÃ§Ã£o possui um campo de metadados associados a cada subconjunto que podemos utilizar para definir os dois domÃ­nios de interesse:
"""

# â•”â•â•¡ 59c355a1-34d5-415b-9e29-afcab5103576
function onandoff(ğ’®)
	Î  = GeoStats.groupby(ğ’®, :ONSHORE)
	
	ONâ‚, ONâ‚‚ = metadata(Î )[:values]
	
	if ONâ‚ == true
		ğ’®â‚›, ğ’®â‚œ = Î 
	else
		ğ’®â‚œ, ğ’®â‚› = Î 
	end
end

# â•”â•â•¡ 340c939a-2a9b-475d-91ef-62effb2a8da3
ğ’®â‚›, ğ’®â‚œ = onandoff(ğ’®)

# â•”â•â•¡ 2c7442fa-5b8c-411d-b3f8-f0ed2ed00dc8
md"""
Para evitar viÃ©s no processo de aprendizado, nÃ³s balancearemos os dados utilizando uma simples tÃ©cnica de **subamostragem**. Essa tÃ©cnica reduz a presenÃ§a da formaÃ§Ã£o majoritÃ¡ria no treinamento de modelos estatÃ­sticos, e Ã© adequada para grandes conjuntos de dados.

Ao aplicar a subamostragem nos poÃ§os `ONSHORE` e `OFFSHORE` obtemos um novo conjunto de dados balanceado com 50% dos exemplos na formaÃ§Ã£o `Manganui` e 50% na formaÃ§Ã£o `Urenui`:
"""

# â•”â•â•¡ a7b23e9e-b3f3-4a8b-a5a7-dae05fd73bf1
function balance(ğ’®)
	# Coluna com anotaÃ§Ãµes
	y  = ğ’®[:FORMATION]
	
	# LocalizaÃ§Ãµes na formaÃ§Ã£o Manganui
	yâ‚ = isequal.(y, "Manganui")
	
	# Contagem de exemplos nas duas formaÃ§Ãµes
	n  = length(y)
	nâ‚ = count(yâ‚)
	nâ‚‚ = n - nâ‚
	
	# Subamostragem dos dados
	if nâ‚ > nâ‚‚
		indsâ‚ = sample(findall(yâ‚), nâ‚‚, replace = false)
		indsâ‚‚ = findall(!, yâ‚)
	else
		indsâ‚ = findall(yâ‚)
		indsâ‚‚ = sample(findall(!, yâ‚), nâ‚, replace = false)
	end
	
	view(ğ’®, [indsâ‚; indsâ‚‚])
end

# â•”â•â•¡ 777f4131-2cbb-4ba5-b786-d6175e3036a5
Î©â‚›, Î©â‚œ = balance(ğ’®â‚›), balance(ğ’®â‚œ)

# â•”â•â•¡ fbd3a1ec-214f-450f-9c2e-547df22157d3
md"""
#### Tarefa de aprendizado

O segundo elemento da definiÃ§Ã£o Ã© a **tarefa de apendizado**. Neste caso, definimos uma Ãºnica tarefa de previsÃ£o de formaÃ§Ã£o a partir de logs, ou seja $\mathcal{T}_s = \mathcal{T}_t$. No jargÃ£o de aprendizado essa tarefa Ã© uma tarefa de classificaÃ§Ã£o:
"""

# â•”â•â•¡ 55151073-083b-433c-96e0-5e51978e888f
ğ’¯ = ClassificationTask(LOGS, :FORMATION)

# â•”â•â•¡ 0250f930-ac62-4fdf-8e36-b79769974a25
md"""
Com isso podemos definir o nosso problema de aprendizado geoestatÃ­stico:
"""

# â•”â•â•¡ a012ef03-64a4-44cb-95c2-a5f734a3f75d
problem = LearningProblem(Î©â‚›, Î©â‚œ, ğ’¯)

# â•”â•â•¡ 12112daa-17f1-445a-93e8-131c35cfb53d
md"""
Como veremos em seguida, nÃ³s podemos resolver o problema com mais de **150** modelos de aprendizado disponÃ­veis no projeto [MLJ.jl](https://github.com/alan-turing-institute/MLJ.jl), incluindo todos os modelos do [scikit-learn](https://scikit-learn.org) e outros modelos de alta performance implementados em Julia:
"""

# â•”â•â•¡ 10ab0262-00ef-4b77-8b6b-a43cf236a29d
models() |> DataFrame

# â•”â•â•¡ 427d35b8-daf0-4d16-87e5-f8eb33e265fe
md"""
> **Nota:** Ã‰ extremamente importante separar a **definiÃ§Ã£o do problema** de aprendizado geostatÃ­stico da **estratÃ©gia de soluÃ§Ã£o** para uma comparaÃ§Ã£o justa de modelos. A maioria dos frameworks clÃ¡ssicos de aprendizado (e.g. scikit-learn) **nÃ£o** permite essa separaÃ§Ã£o.
"""

# â•”â•â•¡ 1ec6e447-fe94-4288-9996-0ba42c8d6cb0
md"""
### 4. SoluÃ§Ã£o do problema

#### Modelos de aprendizado

Com o problema de aprendizado geoestatÃ­stico bem definido, nÃ³s podemos investigar diferentes estratÃ©gias de soluÃ§Ã£o e realizar validaÃ§Ãµes avanÃ§adas que sÃ³ estÃ£o disponÃ­veis no GeoStats.jl.

Primeiro nÃ³s precisamos definir uma lista de modelos de aprendizado para resolver o problema. Estamos interessados em modelos:

1. **Implementados em Julia** por terem uma maior performance computacional.
2. Adequados para a tarefa de **classificaÃ§Ã£o de formaÃ§Ã£o** definida no problema:
    - Modelos **supervisionados** (que aprendem de exemplos de entrada e saÃ­da)
    - Com **variÃ¡vel alvo binÃ¡ria** (que produzem previsÃµes `Manganui` ou `Urenui`)
3. Sob licenÃ§a **MIT** por ser uma licenÃ§a de cÃ³digo aberto permissÃ­vel.

Podemos encontrar esses modelos utilizando filtros na funÃ§Ã£o `models`:
"""

# â•”â•â•¡ 34f48c18-d452-4df4-a8f8-882bfc1db056
models(m -> m.is_pure_julia && m.is_supervised &&
	        m.target_scitype >: AbstractVector{<:Multiclass{2}} &&
	        m.package_license == "MIT") |> DataFrame

# â•”â•â•¡ 2daa903b-af18-40ad-b9ce-0caf93b507c6
md"""
Utilizaremos os seguintes modelos:
"""

# â•”â•â•¡ afa08349-eab0-4ed6-a0aa-cc3cb39a619d
begin
	â„³â‚ = @load DecisionTreeClassifier pkg = DecisionTree
	â„³â‚‚ = @load KNNClassifier          pkg = NearestNeighborModels
	â„³â‚ƒ = @load LogisticClassifier     pkg = MLJLinearModels
	â„³â‚„ = @load ConstantClassifier     pkg = MLJModels
	
	â„³s = [â„³â‚(), â„³â‚‚(), â„³â‚ƒ(), â„³â‚„()]
end

# â•”â•â•¡ b0843d5b-69eb-4a53-bff7-2d3bbd8b0057
md"""
#### EstratÃ©gia de soluÃ§Ã£o

Para que os modelos de aprendizado possam ser utilizados com dados geoespaciais no GeoStats.jl, nÃ³s precisamos definir uma **estratÃ©gia de soluÃ§Ã£o**. A estratÃ©gia de soluÃ§Ã£o mais comum na literatura geoespacial Ã© o que denominamos aprendizado ponto-a-ponto (em inglÃªs "pointwise learning"):
"""

# â•”â•â•¡ 9dd85a75-c1e3-418a-bb3e-7c8875e9c5dd
solvers = [PointwiseLearn(â„³) for â„³ in â„³s];

# â•”â•â•¡ bd82b213-99b2-4ba7-997c-9ddbac69579c
md"""
Essa estratÃ©gia simplesmente **ignora as coordenadas** dos exemplos e trata o dado geoespacial como uma **tabela comum**. Apesar de ser uma estratÃ©gia simplista, ela pode demandar bastante tempo do usuÃ¡rio final que fica responsÃ¡vel pelo prÃ©- e pÃ³s-processamento dos dados em formatos tabulares.

O GeoStats.jl **automatiza esse processo de conversÃ£o** e salva tempo do geocientista interessado em testar diferentes modelos. Em particular, o framework se encarrega de:

1. Treinar o modelo encapsulado no domÃ­nio geoespacial de origem
2. Aplicar o modelo treinado no domÃ­nio geoespacial de destino

onde os domÃ­nios geoespaciais podem ser **qualquer tipo de malha** do projeto [Meshes.jl](https://github.com/JuliaGeometry/Meshes.jl).
"""

# â•”â•â•¡ 3ba896bd-e569-40c3-9fa1-3e79db50bf45
solutions = [solve(problem, solver) for solver in solvers]

# â•”â•â•¡ f66e960b-e38f-4414-be79-09658eb5cf74
md"""
#### AvaliaÃ§Ã£o qualitativa

Podemos facilmente visualizar qualquer uma das soluÃ§Ãµes obtidas. Como o nÃºmero de amostras Ã© considerÃ¡vel neste caso, e nÃ£o estamos utilizando o [Makie.jl](https://github.com/JuliaPlots/Makie.jl) para visualizaÃ§Ãµes 3D, visualizaremos apenas um subconjunto da solucÃ£o i = $(@bind i Scrubbable(1:length(solvers), default=1)):
"""

# â•”â•â•¡ b70f5ab7-9790-4daf-a881-d75c602aaa67
solutionáµ¢ = sample(solutions[i], 10000, replace = false);

# â•”â•â•¡ 5ec99dcc-58b4-4290-8f05-884ef11e464d
plot(solutionáµ¢, marker = (:BrBG_3, 4), colorbar = false,
	 xlabel = "X", ylabel = "Y", zlabel = "Z",
	 title = "PREVISÃƒO DE FORMAÃ‡ÃƒO\n(Manganui = Laranja, Urenui = Verde)")

# â•”â•â•¡ 78d9f9ba-1947-4bec-bc74-b895d084365e
md"""
#### AvaliaÃ§Ã£o quantitativa

Como neste **caso sintÃ©tico** nÃ³s temos acesso ao tipo de formaÃ§Ã£o nos poÃ§os `OFFSHORE`, nÃ³s podemos quantificar o erro de cada modelo utilizado.

Em problemas de classificaÃ§Ã£o, Ã© comum reportar a **matriz de confusÃ£o** para cada modelo. Essa matriz informa o nÃºmero de vezes que uma formaÃ§Ã£o (coluna da matriz) foi classificada pelo modelo como uma certa outra formaÃ§Ã£o (linha da matriz):
"""

# â•”â•â•¡ e6e84f8b-e132-42a7-a0e4-1acd9006dbbb
map(solutions) do Î©Ì‚áµ¢
	# PrevisÃ£o da formaÃ§Ã£o
	yÌ‚ = Î©Ì‚áµ¢[:FORMATION]
	
	# Valor real da formaÃ§Ã£o
	y = Î©â‚œ[:FORMATION]
	
	# Matriz de confusÃ£o
    confmat(yÌ‚, y)
end

# â•”â•â•¡ 653ed159-838c-47d6-878e-0b2530cf7c52
md"""
Observamos que:

- O **modelo mais simples** (logistic) apresenta os **melhores resultados** nos poÃ§os `OFFSHORE`.
- Os **modelos mais complexos** (e.g. decision tree, knn) ficam **"superfitados"** aos poÃ§os `ONSHORE` devido principalmente a quantidade de dados e diferenÃ§a de distribuiÃ§Ã£o `ONSHORE` e `OFFSHORE`.
- O modelo constante apresenta o pior resultado como esperado.

Podemos sumarizar a informaÃ§Ã£o da matriz de confusÃ£o com diferentes medidas, como por exemplo a medida $F_1$-score. A medida Ã© bastante utilizada na Ã¡rea mÃ©dica, e Ã© calculada como

$F_1 = \frac{tp}{tp + \frac{fp + fn}{2}}$

onde $tp$ Ã© o nÃºmero de verdadeiros positivos, $fp$ Ã© o nÃºmero de falsos positivos, e $fn$ Ã© o nÃºmero de falsos negativos. Em geral quanto maior Ã© o $F_1$-score, maior Ã© a performance do modelo:
"""

# â•”â•â•¡ da350067-a8fb-47bc-b9b8-b069e742383b
html"""

<p align="center">

    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png">

</p>

<p align="center">

    <b>Figura 3</b>: IlustraÃ§Ã£o da medida F1-score como combinaÃ§Ã£o de precisÃ£o e recall.

</p>

"""

# â•”â•â•¡ ab970650-8dbd-442b-9a25-4cd871ecd336
map(solutions) do Î©Ì‚áµ¢
	# PrevisÃ£o da formaÃ§Ã£o
	yÌ‚ = Î©Ì‚áµ¢[:FORMATION]
	
	# Valor real da formaÃ§Ã£o
	y = Î©â‚œ[:FORMATION]
	
	# Matriz de confusÃ£o
	f1score(yÌ‚, y)
end

# â•”â•â•¡ 3e469cb8-745d-4f11-a6e7-814f29e1ccef
md"""
Dessa forma, se soubÃ©ssemos o valor real da formaÃ§Ã£o nos poÃ§os `OFFSHORE`, nÃ³s poderÃ­amos escolher o modelo logistic como o melhor modelo segundo o $F_1$-score. Na prÃ¡tica, porÃ©m, **nÃ£o temos as anotaÃ§Ãµes no domÃ­nio geoespacial de destino**, e precisamos de outras mÃ©todos para a seleÃ§Ã£o de modelos.

Antes de investigarmos esses mÃ©todos em detalhe na prÃ³xima seÃ§Ã£o, observamos que existem mais de **50** medidas disponÃ­veis para avaliar modelos de aprendizado quando as anotaÃ§Ãµes sÃ£o conhecidas em um caso sintÃ©tico. Podemos utilizar a funÃ§Ã£o `measures` para descobrir as medidas vÃ¡lidas para as soluÃ§Ãµes encontradas:
"""

# â•”â•â•¡ 5b54c097-07b2-4c26-85b1-c7716cd98145
measures(s -> s.target_scitype >: AbstractVector{<:Multiclass{2}} &&
	          s.prediction_type == :deterministic) |> DataFrame

# â•”â•â•¡ 7d6597a0-ae24-483a-a67f-dd6235acb25e
md"""
### 5. ValidaÃ§Ã£o cruzada


"""

# â•”â•â•¡ e3156d02-0b6d-4720-b44f-4ab7f9a689bc


# â•”â•â•¡ Cell order:
# â•Ÿâ”€32f6d41e-3248-4549-9546-53b34d5aa7c6
# â•Ÿâ”€762a6e04-fcb7-4713-859d-fdbfe8ead1bc
# â•Ÿâ”€32429926-f6c3-44b8-b012-d2c67cad0b6d
# â•Ÿâ”€3c79e7aa-b316-4c4b-b44e-e73312085c20
# â•Ÿâ”€4a3fb559-73dd-41e0-8a11-993e5bf286bf
# â•Ÿâ”€f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
# â•Ÿâ”€1856e01b-2d55-448d-8bdf-e59825934193
# â•Ÿâ”€615e4ed2-f77f-4f38-a6c1-7f0c0f985d49
# â•Ÿâ”€b89139a7-57da-4d9d-a791-c06edd5ab99d
# â•Ÿâ”€8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
# â•Ÿâ”€301d2074-a2d7-44dc-aeb6-29e69ca5348f
# â•Ÿâ”€a0b00451-7418-4d60-812f-5c2a9b32cd4d
# â• â•f4ad710d-f2a0-4110-8e6f-d76f181881ae
# â•Ÿâ”€29cf81d4-996e-4283-8d72-63d3ed1f55a7
# â•Ÿâ”€fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
# â•Ÿâ”€6f400014-4f12-42ec-8ee8-db181d82f656
# â•Ÿâ”€a280a283-59c3-4728-9110-b91d5ea63568
# â•Ÿâ”€bfdbec36-069d-422d-8f88-fd97f8d85455
# â• â•b6b9f6db-5d69-496b-9862-bf7d6add901b
# â•Ÿâ”€2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
# â•Ÿâ”€c2fbca00-a248-4f9e-9754-08fd47225bed
# â• â•b106e967-13c3-483d-bc53-9772c25947be
# â• â•e912de0f-cab2-4e11-b0bd-6a9603a9e966
# â•Ÿâ”€ce132078-cfd3-4455-98b4-3297b1be405f
# â•Ÿâ”€4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
# â•Ÿâ”€4eadc228-7905-4328-ab01-f21339dd40aa
# â•Ÿâ”€3855a6d5-7b8a-487b-abad-288f9fc0152d
# â• â•eb9d3014-65b2-44f7-8d33-445826e6974b
# â•Ÿâ”€4b41d46e-ccf0-4232-8ce8-f9520a90efea
# â• â•a1c4fc51-1878-4c13-8d01-3642d23ee670
# â•Ÿâ”€c10c7845-61ec-4275-b9a0-4934a7848e9b
# â• â•d70ac330-0aae-4fae-91a2-159f1c1bc11f
# â• â•44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
# â•Ÿâ”€32f8bc26-97e4-4cfa-b064-eebe0403accb
# â• â•dcc82e49-af10-4f9c-927d-1cf039a6185a
# â• â•86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
# â• â•6d1b48f9-c7c6-461d-9908-f2a36de2694f
# â•Ÿâ”€4c76d345-1d77-4f7f-9fbe-2d4707d70b29
# â•Ÿâ”€06e19a21-5a4e-48c0-9030-9c6c43a3afdb
# â•Ÿâ”€e3c46f60-b32e-4911-971f-230c87507f37
# â•Ÿâ”€0e168bfe-902b-4732-8ecb-a9a75b330bbb
# â• â•8ee75575-d2f2-409f-9016-dac048fc6ff6
# â•Ÿâ”€a21d65cb-d369-4e9b-a1a6-53b06b09dc22
# â• â•cb8d9a31-d415-45b7-a743-15c715dfd2a5
# â•Ÿâ”€8712e1ec-0b84-4fc4-a44e-6f5a91180b8b
# â• â•59c355a1-34d5-415b-9e29-afcab5103576
# â• â•340c939a-2a9b-475d-91ef-62effb2a8da3
# â•Ÿâ”€2c7442fa-5b8c-411d-b3f8-f0ed2ed00dc8
# â• â•a7b23e9e-b3f3-4a8b-a5a7-dae05fd73bf1
# â• â•777f4131-2cbb-4ba5-b786-d6175e3036a5
# â•Ÿâ”€fbd3a1ec-214f-450f-9c2e-547df22157d3
# â• â•55151073-083b-433c-96e0-5e51978e888f
# â•Ÿâ”€0250f930-ac62-4fdf-8e36-b79769974a25
# â• â•a012ef03-64a4-44cb-95c2-a5f734a3f75d
# â•Ÿâ”€12112daa-17f1-445a-93e8-131c35cfb53d
# â• â•10ab0262-00ef-4b77-8b6b-a43cf236a29d
# â•Ÿâ”€427d35b8-daf0-4d16-87e5-f8eb33e265fe
# â•Ÿâ”€1ec6e447-fe94-4288-9996-0ba42c8d6cb0
# â• â•34f48c18-d452-4df4-a8f8-882bfc1db056
# â•Ÿâ”€2daa903b-af18-40ad-b9ce-0caf93b507c6
# â• â•afa08349-eab0-4ed6-a0aa-cc3cb39a619d
# â•Ÿâ”€b0843d5b-69eb-4a53-bff7-2d3bbd8b0057
# â• â•9dd85a75-c1e3-418a-bb3e-7c8875e9c5dd
# â•Ÿâ”€bd82b213-99b2-4ba7-997c-9ddbac69579c
# â• â•3ba896bd-e569-40c3-9fa1-3e79db50bf45
# â•Ÿâ”€f66e960b-e38f-4414-be79-09658eb5cf74
# â• â•b70f5ab7-9790-4daf-a881-d75c602aaa67
# â• â•5ec99dcc-58b4-4290-8f05-884ef11e464d
# â•Ÿâ”€78d9f9ba-1947-4bec-bc74-b895d084365e
# â• â•e6e84f8b-e132-42a7-a0e4-1acd9006dbbb
# â•Ÿâ”€653ed159-838c-47d6-878e-0b2530cf7c52
# â•Ÿâ”€da350067-a8fb-47bc-b9b8-b069e742383b
# â• â•ab970650-8dbd-442b-9a25-4cd871ecd336
# â•Ÿâ”€3e469cb8-745d-4f11-a6e7-814f29e1ccef
# â• â•5b54c097-07b2-4c26-85b1-c7716cd98145
# â•Ÿâ”€7d6597a0-ae24-483a-a67f-dd6235acb25e
# â• â•e3156d02-0b6d-4720-b44f-4ab7f9a689bc
