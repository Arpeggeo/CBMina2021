### A Pluto.jl notebook ###
# v0.14.2

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : missing
        el
    end
end

# â•”â•â•¡ 32f6d41e-3248-4549-9546-53b34d5aa7c6
begin
	# instantiate environment
	using Pkg; Pkg.activate(@__DIR__); Pkg.instantiate()

	# load packages used in this notebook
	using GeoStats, MLJ
	using CSV, DataFrames
	using Distributions
	using PlutoUI
	using Plots
	using StatsPlots

	# default plot settings
	gr(format=:png)
end;

# â•”â•â•¡ 762a6e04-fcb7-4713-859d-fdbfe8ead1bc
html"""
<p style="background-color:lightgrey" xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">GeoStats.jl at CBMina</span> by <span property="cc:attributionName">JÃºlio Hoffimann & Franco Naghetini</span> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>
"""

# â•”â•â•¡ 32429926-f6c3-44b8-b012-d2c67cad0b6d
md"""
![geostats-logo](https://github.com/JuliaEarth/GeoStats.jl/blob/master/docs/src/assets/logo-text.svg?raw=true)

# GeostatÃ­stica moderna

Instrutores: [JÃºlio Hoffimann](https://juliohm.github.io) & [Franco Naghetini](https://github.com/fnaghetini)
"""

# â•”â•â•¡ 3c79e7aa-b316-4c4b-b44e-e73312085c20
md"""
## Aprendizado geoestatÃ­stico

Neste mÃ³dulo aprenderemos sobre esta nova Ã¡rea denominada **aprendizado geoestatÃ­stico** ([Hoffimann et al 2021](https://arxiv.org/abs/2102.08791)). Introduziremos os elementos do problema de aprendizado com **dados geoespaciais**, e veremos como a biblioteca [GeoStats.jl](https://github.com/JuliaEarth/GeoStats.jl) estÃ¡ na vanguarda desta tecnologia.

Existem questÃµes teÃ³ricas muito interessantes que nÃ£o cobriremos neste minicurso, e que estÃ£o sendo desenvolvidas ativamente no projeto. Nos concentraremos aqui em **exemplos prÃ¡ticos** para que vocÃª possa adaptar este notebook aos seus prÃ³prios desafios na mineraÃ§Ã£o.
"""

# â•”â•â•¡ 4a3fb559-73dd-41e0-8a11-993e5bf286bf
html"""
<iframe width="560" height="315" src="https://www.youtube.com/embed/6S_9GLMv3xI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
"""

# â•”â•â•¡ f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
md"""
Ao final deste mÃ³dulo vocÃª serÃ¡ capaz de:

- Identificar os **elementos do aprendizado geoestatÃ­stico** na mineraÃ§Ã£o
- Definir o **problema de aprendizado** de forma clara com o GeoStats.jl
- Resolver o problema com vÃ¡rios **modelos de aprendizado** disponÃ­veis

### Agenda

1. Aprendizado **geo**estatÃ­stico
    - O que Ã© aprendizado de mÃ¡quina (a.k.a. ML)?
    - A nova Ã¡rea de aprendizado **geo**estatÃ­stico
    - Os elementos do aprendizado **geo**estatÃ­stico
2. Exemplos prÃ¡ticos com o GeoStats.jl
    - Exemplo 1
    - Exemplo 2
"""

# â•”â•â•¡ 1856e01b-2d55-448d-8bdf-e59825934193
md"""
### 1. Aprendizado geoestatÃ­stico

#### O que Ã© o aprendizado de mÃ¡quina?

Antes de podermos entender o problema de aprendizado **geo**estatÃ­stico, isto Ã©, o problema de aprendizado com dados **geoespacias**, precisamos entender o problema mais simples de **aprendizado de mÃ¡quina** introduzido na ciÃªncia da computaÃ§Ã£o na Ã¡rea de **inteligÃªncia artificial**.

Nessa Ã¡rea, buscam-se criar tecnologias capazes de "imitar" a inteligÃªncia humana. Ao invÃ©s de tentarmos definir inteligÃªncia, vamos nos concentrar em duas habilidades que nÃ³s humanos exercermos todo dia:

1. A habilidade de **raciocinar sobre fatos**
2. A habilidade **aprender com experiÃªncia**

A habilidade de **raciocÃ­nio** Ã© o que nos permite gerar conclusÃµes sobre fatos, segundo alguma lÃ³gica prÃ©-estabelecida. Por exemplo, geocientistas sÃ£o capazes de imaginar sistemas deposicionais na subsuperfÃ­cie a quilÃ´metros de profundidade utilizando regras de probabilidade em cima de conhecimento prÃ©-estabelecido na literatura. [Hoffimann et al 2021. Probabilistic Knowledge-based Characterization of Conceptual Geological Models](https://www.sciencedirect.com/science/article/pii/S2590197421000033).
"""

# â•”â•â•¡ 8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
html"""

<p align="center">

    <img src="https://ars.els-cdn.com/content/image/1-s2.0-S2590197421000033-gr1.jpg">

</p>

<p align="center">

    <b>Figura 1</b>: Modelo geolÃ³gico conceitual e possÃ­veis cenÃ¡rios geolÃ³gicos para o sistema deposicional: Braided Rivers, Fluvial Delta, Continental Slope, Inner Shelf.

</p>

"""

# â•”â•â•¡ 301d2074-a2d7-44dc-aeb6-29e69ca5348f
md"""
> **Nota:**
> MÃ©todos de raciocÃ­nio funcionam bem em problemas onde hÃ¡ um enorme acervo de conhecimento. SÃ£o Ã³timos quando (1) poucos dados estÃ£o disponÃ­veis sobre um determinado objeto de estudo, e (2) a literatura Ã© irrefutÃ¡vel.
"""

# â•”â•â•¡ a0b00451-7418-4d60-812f-5c2a9b32cd4d
md"""
A habilidade de **aprendizado**, por outro lado, Ã© o que nos permite **gerar novas regras** baseadas em experiÃªncias presentes. Ã‰ com essa habilidade que evoluimos o nosso entendimento de mundo e criamos novas conexÃµes sobre o ambiente em que operamos.

De forma mais precisa, podemos definir aprendizado em termos de experiÃªncia $E$, tarefa $T$ a ser executada e medida de performance $P$ nessa tarefa. Adotaremos a definiÃ§Ã£o do [Mitchell 1997](http://www.cs.cmu.edu/~tom/mlbook.html):

**DefiniÃ§Ã£o (Aprendizado).** *Dizemos que um agente (e.g. programa de computador) aprende com a experiÃªncia $E$ em relacÃ£o Ã  tarefa $T$ e Ã  medida de performance $P$ se a performance, medida por $P$, melhora com a experiÃªncia $E$.*

Por exemplo, um programa de computador pode aprender a jogar xadrez jogando partidas contra si mesmo. A medida de performance pode ser o nÃºmero de partidas ganhas em um sÃ©rie de 10 partidas, e nesse caso cada Ã© uma experiÃªncia nova adquirida.

Aqui estamos interessados no **aprendizado estatÃ­stico** que consiste de aprender novas regras utilizando grandes bases de dados como furos de sondagem, dados oriundos da geometalurgia, e imagens de satÃ©lite. Em particular, estamos interessados na aplicacÃ£o dessa teoria por meio de programas de computador, conhecida como **aprendizado de mÃ¡quina** (em inglÃªs "machine learning" ou "ML").

A teoria de aprendizado estatÃ­stico estÃ¡ por trÃ¡s de diversas tecnologias atuais, especialmente o **aprendizado estatÃ­stico supervisionado** que consiste em aprender uma funÃ§Ã£o *desconhecida* $f\colon x \mapsto y$ por meio de vÃ¡rios exemplos $\left\{(x_1,y_1), (x_2,y_2),\ldots,(x_n,y_n)\right\}$ de entrada e saÃ­da da funÃ§Ã£o:
"""

# â•”â•â•¡ 29cf81d4-996e-4283-8d72-63d3ed1f55a7
md"""
T: $(@bind T Slider(0.1:0.1:1, default=0.3, show_value=true))

n: $(@bind n Slider(100:100:500, show_value=true))
"""

# â•”â•â•¡ f4ad710d-f2a0-4110-8e6f-d76f181881ae
f(x) = sin(x / T)

# â•”â•â•¡ fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
begin
	xs = rand(Normal(), n)
	ys = f.(xs) .+ rand(Normal(0,0.1), n)
	
	plot(f, -1, 1, color = :green, label = "f(x)",
		 xlims = (-1, 1), ylims = (-1, 1),
		 xlabel = "x", ylabel = "y",
	     title = "Como aprender f(x)?")
	scatter!([(x, -1) for x in xs], label = "xâ‚, xâ‚‚, ..., xâ‚™",
	         marker = (:spike, 10, :black))
	scatter!(collect(zip(xs, ys)), label = "yâ‚, yâ‚‚, ..., yâ‚™",
	         marker = (:circle, 3, :black))
end

# â•”â•â•¡ 6f400014-4f12-42ec-8ee8-db181d82f656
md"""
Quanto mais complexa Ã© a funÃ§Ã£o $f$, mais exemplos sÃ£o necessÃ¡rios para aprendÃª-la segundo alguma medida de performance (e.g. erro quadrÃ¡tico). Por exemplo, se o perÃ­odo de oscilaÃ§Ã£o $T / 2\pi$ da funÃ§Ã£o for baixo, mais densa terÃ¡ que ser a amostragem do eixo $x$ para um aprendizado bem sucedido.

Observamos que:

- O eixo $x$ no aprendizado clÃ¡ssico representa uma **propriedade ou caracterÃ­stica** do exemplo. Por exemplo, o mÃ³dulo de Young ou o teor de um certo minÃ©rio numa amostra.
- O eixo $y$ representa uma **propriedade que se quer prever**, e que estÃ¡ relacionada de alguma forma com a propriedade $x$.
"""

# â•”â•â•¡ a280a283-59c3-4728-9110-b91d5ea63568
md"""
> **Nota:**
> MÃ©todos de aprendizado estatÃ­stico funcionam bem em problemas onde hÃ¡ uma grande quantidade de dados (os exemplos), preferencialmente anotados por especialistas.
"""

# â•”â•â•¡ bfdbec36-069d-422d-8f88-fd97f8d85455
md"""
#### Aprendizado geoestatÃ­stico

A **teoria de aprendizado clÃ¡ssica** utilizada no desenvolvimento de vÃ¡rios mÃ©todos de aprendizado de mÃ¡quina **nÃ£o Ã© apropriada para lidar com dados geoespaciais**, principalmente porque a maior parte da literatura assume que:

1. A distribuiÃ§Ã£o das propriedades dos exemplos Ã© fixa.
2. Os exemplos  sÃ£o independentes e identicamente distribuÃ­dos (I.I.D.).
3. Os exemplos tem um suporte amostral (ou volume fÃ­sico) comum.

Recentemente, nÃ³s formalizamos o problema de **aprendizado geoestatÃ­stico** (em inglÃªs "geostatistical learning" ou "GL") com o intuito de resolver grandes desafios de aprendizado de mÃ¡quina com dados geoespaciais. [Hoffimann et al 2021. Geostatistical Learning: Challenges and Opportunities](https://arxiv.org/abs/2102.08791).

Para ilustrar esses desafios, vamos considerar um conjunto de dados de poÃ§os de petrÃ³leo que construÃ­mos de fontes pÃºblicas da Nova ZelÃ¢ndia ([Carvalho et al. 2020](https://zenodo.org/record/3832955#.YHmR9EOYU3w)):
"""

# â•”â•â•¡ b6b9f6db-5d69-496b-9862-bf7d6add901b
table = CSV.File("data/taranaki/logs.csv") |> DataFrame

# â•”â•â•¡ 2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
md"""
e uma tarefa de aprendizado que consiste em prever o tipo de formaÃ§Ã£o da rocha ($y$ = `FORMATION`) em poÃ§os `OFFSHORE` como funÃ§Ã£o de perfis (ou "logs") eletromagnÃ©ticos ($x$ = (`GR`, `SP`, ...)) e com base em anotaÃ§Ãµes $y_i = f(x_i)$ feitas por especialistas em poÃ§os `ONSHORE` de mais fÃ¡cil acesso.
"""

# â•”â•â•¡ c2fbca00-a248-4f9e-9754-08fd47225bed
md"""
##### FalsificaÃ§Ã£o da hipÃ³tese 1

Por simplicidade, eliminaremos as linhas da tabela com dados faltantes para os logs `GR`, `SP`, `DENS`, `NEUT` e `DTC`, e manteremos apenas as linhas com formaÃ§Ãµes `Urenui` e `Manganui`:
"""

# â•”â•â•¡ b106e967-13c3-483d-bc53-9772c25947be
begin
	# Dados utilizados
	LOGS  = [:GR,:SP,:DENS,:NEUT,:DTC]
	CATEG = [:FORMATION, :ONSHORE]
	COORD = [:X, :Y, :Z]
	FORMS = ["Urenui", "Manganui"]
	
	# OperaÃ§Ãµes de limpeza dos dados
	f1(table) = select(table, [LOGS; CATEG; COORD])
	f2(table) = dropmissing(table)
	f3(table) = filter(row -> row.FORMATION âˆˆ FORMS, table)
	
	# Sequenciamento de operaÃ§Ãµes
	samples = table |> f1 |> f2 |> f3
end

# â•”â•â•¡ 9e6849d8-4c4b-4b18-a12e-734b45f9e41f
md"""
Para facilitar a interpretaÃ§Ã£o dos dados e o posterior treinamento de modelos de aprendizado, nÃ³s normalizaremos os logs para que tenham mÃ©dia zero e desvio padrÃ£o unitÃ¡rio:
"""

# â•”â•â•¡ 48a4fdfb-07d8-4ce9-a489-5f9611ed4c5b
for LOG in LOGS
	# Seleciona coluna com o log
	x = samples[!, LOG]
	
	# Calcula mÃ©dia e desvio padrÃ£o
	Î¼ = mean(x)
	Ïƒ = std(x, mean = Î¼)
	
	# Normaliza coluna
	samples[!, LOG] = (x .- Î¼) ./ Ïƒ
end

# â•”â•â•¡ e912de0f-cab2-4e11-b0bd-6a9603a9e966
describe(samples)

# â•”â•â•¡ ce132078-cfd3-4455-98b4-3297b1be405f
md"""
Como a tarefa de aprendizado que definimos consiste em prever a formaÃ§Ã£o em poÃ§os `OFFSHORE` baseado em anotaÃ§Ãµes em poÃ§os `ONSHORE`, nÃ³s visualizaremos os dados agrupados dessa forma. Em particular, nÃ³s queremos investigar a **distribuiÃ§Ã£o bivariada** entre o logs $(@bind X1 Select(string.(LOGS))) e $(@bind X2 Select(string.(LOGS), default="SP")) nesse agrupamento:
"""

# â•”â•â•¡ 4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
begin
	# Agrupamento em pocos onshore and offshore
	G1, G2 = DataFrames.groupby(samples, :ONSHORE)
	
	T1 = G1.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	T2 = G2.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	
	p1 = scatter(G1[!,X1], G1[!,X2], marker = (:gray, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T1)
	p2 = scatter(G2[!,X1], G2[!,X2], marker = (:purple, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T2)
	
	plot(p1, p2, link = :both, aspect_ratio = :equal, size = (700, 400))
end

# â•”â•â•¡ 4eadc228-7905-4328-ab01-f21339dd40aa
md"""
Da visualizaÃ§Ã£o concluimos que a hipÃ³tese (1) da teoria clÃ¡ssica nÃ£o Ã© vÃ¡lida neste caso. Isto Ã©, a **distribuiÃ§Ã£o das propriedades dos exemplos varia drasticamente** de um domÃ­nio geolÃ³gico para outro, mesmo quando consideramos um subconjunto pequeno dos dados para duas formaÃ§Ãµes localizadas em uma Ãºnica bacia.
"""

# â•”â•â•¡ 3855a6d5-7b8a-487b-abad-288f9fc0152d
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 2

Vejamos agora a hipÃ³tese (2) da teoria clÃ¡ssica que assume que exemplos utilizados no treinamento de um modelo de aprendizado sÃ£o amostrados de forma independente no espaÃ§o de propriedades.

Para avaliarmos essa hipÃ³tese, utilizaremos a **anÃ¡lise variogrÃ¡fica**. O GeoStats.jl possui estimadores de variogramas de alta performance que conseguem lidar com **centenas de milhares** de amostras em poucos segundos. [Hoffimann & Zadrozny. 2019. Efficient variography with partition variograms.](https://www.sciencedirect.com/science/article/pii/S0098300419302936).

Para utilizar esses estimadores, nÃ³s precisaremos **georreferenciar a tabela** de amostras em um dado geoespacial do GeoStats.jl que chamamos de `GeoData`. Esse dado se comporta como uma tabela comum, mas adicionalmente armazena informaÃ§Ãµes necessÃ¡rias para anÃ¡lises geoespaciais.

AlÃ©m de georreferenciar as amostras, nÃ³s iremos aproveitar esta etapa de processamento para especificar o **tipo cientÃ­fico** de cada variÃ¡vel da tabela. Por padrÃ£o esses tipos sÃ£o inferidos pela linguagem como:
"""

# â•”â•â•¡ eb9d3014-65b2-44f7-8d33-445826e6974b
schema(samples)

# â•”â•â•¡ 4b41d46e-ccf0-4232-8ce8-f9520a90efea
md"""
NÃ³s iremos converter os tipos cientÃ­ficos `Textual` e `Count` das variÃ¡veis `FORMATION` e `ONSHORE` pelo tipo `Multiclass` que representa uma variÃ¡vel categÃ³rica.

Por fim, nÃ³s iremos eliminar todas as amostras com coordenadas geogrÃ¡ficas repetidas jÃ¡ que procedimentos de variografia requerem unicidade de coordenadas.

Em resumo, nÃ³s utilizaremos:

1. A funÃ§Ã£o `coerce` para especificar o tipo cientÃ­fico das variÃ¡veis `FORMATION` e `ONSHORE`.
2. A funÃ§Ã£o `georef` para georreferenciar as amostras utilizando as coordenadas `X`, `Y` e `Z`.
3. A funÃ§Ã£o `uniquecoords` para eliminar amostras com coordenadas repetidas.
"""

# â•”â•â•¡ a1c4fc51-1878-4c13-8d01-3642d23ee670
begin
	# OperaÃ§Ãµes de processamento
	g1(table) = coerce(table, :FORMATION => Multiclass, :ONSHORE => Multiclass)
	g2(table) = georef(table, (:X, :Y, :Z))
	g3(table) = uniquecoords(table)
	
	# Sequenciamento de operaÃ§Ãµes
	ğ’® = samples |> g1 |> g2 |> g3 |> GeoData
end

# â•”â•â•¡ c10c7845-61ec-4275-b9a0-4934a7848e9b
md"""
Em seguida calculamos o variograma direcional (vertical) ao longo da direÃ§Ã£o dos poÃ§os:
"""

# â•”â•â•¡ d70ac330-0aae-4fae-91a2-159f1c1bc11f
Î³ = DirectionalVariogram((0.,0.,1.), ğ’®, :GR, maxlag = 100., nlags = 50, dtol = 10.)

# â•”â•â•¡ 44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
plot(Î³)

# â•”â•â•¡ 32f8bc26-97e4-4cfa-b064-eebe0403accb
md"""
O comprimento de correlaÃ§Ã£o ou "range" positivo do variograma indica a dependÃªncia espacial das amostras, e pode ser estimado por mÃ­nimos quadrados ponderados:
"""

# â•”â•â•¡ dcc82e49-af10-4f9c-927d-1cf039a6185a
Î³â‚œ = fit(Variogram, Î³, h -> exp(-h/20))

# â•”â•â•¡ 86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
range(Î³â‚œ)

# â•”â•â•¡ 6d1b48f9-c7c6-461d-9908-f2a36de2694f
plot(Î³); plot!(Î³â‚œ, 0, 100)

# â•”â•â•¡ 4c76d345-1d77-4f7f-9fbe-2d4707d70b29
md"""
A partir da anÃ¡lise variogrÃ¡fica, concluimos que a hipÃ³tese (2) tambÃ©m nÃ£o Ã© valida neste caso. As amostras sÃ£o adjacentes no espaÃ§o fÃ­sico, e estÃ£o mais prÃ³ximas entre si do que o comprimento de correlaÃ§Ã£o do processo. Ou seja, as **amostras estÃ£o associadas geoespacialmente**.
"""

# â•”â•â•¡ 06e19a21-5a4e-48c0-9030-9c6c43a3afdb
md"""
#### FalsificaÃ§Ã£o da hipÃ³tese 3

A hipÃ³tese (3) nÃ£o Ã© valida, pois como discutimos no primeiro dia do minicurso, amostras geofÃ­sicas geralmente tem um suporte (ou volume fÃ­sico) variÃ¡vel. Neste caso, **o espaÃ§amento das amostras ao longo dos poÃ§os nÃ£o Ã© constante**.
"""

# â•”â•â•¡ e3c46f60-b32e-4911-971f-230c87507f37
md"""
#### Resumo

- A **anÃ¡lise bivariada** indicou que as **distribuiÃ§Ãµes das propriedades** em poÃ§os `ONSHORE` e `OFFSHORE` **sÃ£o distintas**. Portanto, nÃ£o Ã© aconselhÃ¡vel treinar um modelo de aprendizado com anotaÃ§Ãµes em poÃ§os `ONSHORE` e aplicÃ¡-lo diretamente a poÃ§os `OFFSHORE`, e vice versa.

- A **anÃ¡lise variogrÃ¡fica** indicou a **existÃªncia de correlaÃ§Ã£o linear** ao longo dos poÃ§os. Isso significa que modelos de aprendizado clÃ¡ssicos desenvolvidos assumindo independÃªncia de exemplos podem apresentar, e geralmente apresentam, deterioraÃ§Ã£o de performance em aplicaÃ§Ãµes prÃ¡ticas em geociÃªncias.

Precisamos de uma nova definiÃ§Ã£o de aprendizado com dados geoespaciais, que chamaremos de **aprendizado geoestatÃ­stico** ou GL:

**DefiniÃ§Ã£o (GL).** *Dado um domÃ­nio geoespacial de origem $\mathcal{D}_s$ (ou "source") e uma tarefa de aprendizado $\mathcal{T}_s$, e um domÃ­nio de destino $\mathcal{D}_t$ (ou "target") e uma tarefa de aprendizado $\mathcal{T}_t$. O aprendizado geoestatÃ­stico consiste em aprender a tarefa $\mathcal{T}_t$ no domÃ­nio $\mathcal{D}_t$ utilizando o conhecimento adquirido no aprendizado da tarefa $\mathcal{T}_s$ no domÃ­nio $\mathcal{D}_s$. Assumindo que as propriedades em $\mathcal{D}_s$ e $\mathcal{D}_t$ sÃ£o uma Ãºnica realizaÃ§Ã£o dos processos envolvidos.*
"""

# â•”â•â•¡ 0e168bfe-902b-4732-8ecb-a9a75b330bbb
md"""
#### Elementos do aprendizado geoestatÃ­stico

Para esclarecer a definiÃ§Ã£o de GL, continuaremos explorando os dados de New Zealand. O primeiro elemento da definiÃ§Ã£o Ã© o **domÃ­nio geoespacial** onde dados estÃ£o disponÃ­veis. Definimos dois domÃ­nios:

- O **domÃ­nio de origem** $\mathcal{D}_s$ representa as trajetÃ³rias dos poÃ§os `ONSHORE`. Nesse domÃ­nio estÃ£o disponÃ­veis os logs, assim como as anotaÃ§Ãµes do tipo de formaÃ§Ã£o feitas por especialistas.
- O **domÃ­nio de destino** $\mathcal{D}_t$ representa as trajetÃ³rias dos poÃ§os `OFFSHORE`. Nesse domÃ­nio estÃ£o disponÃ­veis apenas os logs que serÃ£o utilizados pelo modelo de aprendizao para previsÃ£o do tipo de formaÃ§Ã£o.

Vemos que os nossos dados geoespaciais estÃ£o definidos em um domÃ­nio do tipo `PointSet`:
"""

# â•”â•â•¡ 8ee75575-d2f2-409f-9016-dac048fc6ff6
domain(ğ’®)

# â•”â•â•¡ a21d65cb-d369-4e9b-a1a6-53b06b09dc22
md"""
E que a tabela de valores associada a esse domÃ­nio contÃ©m as seguintes variÃ¡veis:
"""

# â•”â•â•¡ cb8d9a31-d415-45b7-a743-15c715dfd2a5
values(ğ’®) |> DataFrame

# â•”â•â•¡ 8712e1ec-0b84-4fc4-a44e-6f5a91180b8b
md"""
Queremos particionar esse dado geoespacial de acordo com a coluna `ONSHORE`. Existem vÃ¡rias maneiras de obter esse resultado, como por exemplo:
"""

# â•”â•â•¡ 75d031cd-b55f-4d8a-89fd-3acb11a551ef
Î  = GeoStats.groupby(ğ’®, :ONSHORE)

# â•”â•â•¡ 1218bb53-fd4e-4574-ba62-e67f955ba0a8
md"""
Essa partiÃ§Ã£o contem um campo de metadados associados a cada subconjunto da partiÃ§Ã£o, que podemos utilizar para definir os dois dados geoespaciais de interesse, com seus respectivos domÃ­nios:
"""

# â•”â•â•¡ 59c355a1-34d5-415b-9e29-afcab5103576
begin
	ON1, ON2 = metadata(Î )[:values]
	
	if ON1 == true
		ğ’®â‚›, ğ’®â‚œ = Î 
	else
		ğ’®â‚œ, ğ’®â‚› = Î 
	end
end;

# â•”â•â•¡ 7e9c42eb-c70f-4269-8b5e-b8cddbdc692b
ğ’Ÿâ‚› = domain(ğ’®â‚›)

# â•”â•â•¡ 6300bcd6-44e4-4d2a-8e7d-dc7162eaea78
ğ’Ÿâ‚œ = domain(ğ’®â‚œ)

# â•”â•â•¡ fbd3a1ec-214f-450f-9c2e-547df22157d3
md"""
O segundo elemento da definiÃ§Ã£o Ã© a **tarefa de apendizado**. Neste exemplo, definimos uma Ãºnica tarefa de previsÃ£o de formaÃ§Ã£o a partir de logs, ou seja $\mathcal{T}_s = \mathcal{T}_t$. No jargÃ£o de aprendizado essa tarefa Ã© uma tarefa de classificaÃ§Ã£o:
"""

# â•”â•â•¡ 55151073-083b-433c-96e0-5e51978e888f
ğ’¯ = ClassificationTask(LOGS, :FORMATION)

# â•”â•â•¡ 0250f930-ac62-4fdf-8e36-b79769974a25
md"""
Com isso podemos definir o nosso problema de aprendizado geoestatÃ­stico:
"""

# â•”â•â•¡ a012ef03-64a4-44cb-95c2-a5f734a3f75d
ğ’« = LearningProblem(ğ’®â‚›, ğ’®â‚œ, ğ’¯)

# â•”â•â•¡ 12112daa-17f1-445a-93e8-131c35cfb53d
md"""
e resolvÃª-lo com mais de **150** modelos de aprendizado disponÃ­veis no projeto [MLJ.jl](https://github.com/alan-turing-institute/MLJ.jl), incluindo todos os modelos do [scikit-learn](https://scikit-learn.org) e outros modelos de alta performance implementados em Julia:
"""

# â•”â•â•¡ 10ab0262-00ef-4b77-8b6b-a43cf236a29d
models() |> DataFrame

# â•”â•â•¡ 1ec6e447-fe94-4288-9996-0ba42c8d6cb0
md"""
Estamos interessados em modelos:

1. **Implementados em Julia** por terem uma maior performance computacional em grandes conjuntos de dados como os dados de New Zealand.
2. Adequados para a tarefa de **classificaÃ§Ã£o de formaÃ§Ã£o** definida no problema:
    - Modelos **supervisionados** (que aprendem de exemplos de entrada e saÃ­da)
    - Com **variÃ¡vel alvo binÃ¡ria** (que produzem previsÃµes `Urenui` ou `Manganui`)
3. Sob licenÃ§a **MIT** por ser uma licenÃ§a de cÃ³digo aberto flexÃ­vel e Ã³tima para qualquer tipo de projeto acadÃªmico ou industrial.

Podemos facilmente encontrar esses modelos utilizando filtros na funÃ§Ã£o `models`:
"""

# â•”â•â•¡ 34f48c18-d452-4df4-a8f8-882bfc1db056
models(m -> m.is_pure_julia && m.is_supervised &&
	        m.target_scitype >: AbstractVector{<:Multiclass{2}} &&
	        m.package_license == "MIT") |> DataFrame

# â•”â•â•¡ 2daa903b-af18-40ad-b9ce-0caf93b507c6
md"""
Iremos utilizar os seguintes modelos da lista:
"""

# â•”â•â•¡ afa08349-eab0-4ed6-a0aa-cc3cb39a619d
begin
	â„³â‚ = @load DecisionTreeClassifier pkg = DecisionTree
	â„³â‚‚ = @load KNNClassifier          pkg = NearestNeighborModels
	â„³â‚ƒ = @load LogisticClassifier     pkg = MLJLinearModels
	â„³â‚„ = @load ConstantClassifier     pkg = MLJModels
	
	â„³s = [â„³â‚(), â„³â‚‚(), â„³â‚ƒ(), â„³â‚„()]
end

# â•”â•â•¡ bd1738fb-26f3-4ef8-a43c-f4c3740c46cb
md"""
### 2. Exemplos de aprendizado geoestatÃ­stico
"""

# â•”â•â•¡ 74f940f3-5c76-4f7e-a46a-12038d7584c7


# â•”â•â•¡ Cell order:
# â•Ÿâ”€32f6d41e-3248-4549-9546-53b34d5aa7c6
# â•Ÿâ”€762a6e04-fcb7-4713-859d-fdbfe8ead1bc
# â•Ÿâ”€32429926-f6c3-44b8-b012-d2c67cad0b6d
# â•Ÿâ”€3c79e7aa-b316-4c4b-b44e-e73312085c20
# â•Ÿâ”€4a3fb559-73dd-41e0-8a11-993e5bf286bf
# â•Ÿâ”€f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
# â•Ÿâ”€1856e01b-2d55-448d-8bdf-e59825934193
# â•Ÿâ”€8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
# â•Ÿâ”€301d2074-a2d7-44dc-aeb6-29e69ca5348f
# â•Ÿâ”€a0b00451-7418-4d60-812f-5c2a9b32cd4d
# â• â•f4ad710d-f2a0-4110-8e6f-d76f181881ae
# â•Ÿâ”€29cf81d4-996e-4283-8d72-63d3ed1f55a7
# â•Ÿâ”€fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
# â•Ÿâ”€6f400014-4f12-42ec-8ee8-db181d82f656
# â•Ÿâ”€a280a283-59c3-4728-9110-b91d5ea63568
# â•Ÿâ”€bfdbec36-069d-422d-8f88-fd97f8d85455
# â• â•b6b9f6db-5d69-496b-9862-bf7d6add901b
# â•Ÿâ”€2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
# â•Ÿâ”€c2fbca00-a248-4f9e-9754-08fd47225bed
# â• â•b106e967-13c3-483d-bc53-9772c25947be
# â•Ÿâ”€9e6849d8-4c4b-4b18-a12e-734b45f9e41f
# â• â•48a4fdfb-07d8-4ce9-a489-5f9611ed4c5b
# â• â•e912de0f-cab2-4e11-b0bd-6a9603a9e966
# â•Ÿâ”€ce132078-cfd3-4455-98b4-3297b1be405f
# â•Ÿâ”€4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
# â•Ÿâ”€4eadc228-7905-4328-ab01-f21339dd40aa
# â•Ÿâ”€3855a6d5-7b8a-487b-abad-288f9fc0152d
# â• â•eb9d3014-65b2-44f7-8d33-445826e6974b
# â•Ÿâ”€4b41d46e-ccf0-4232-8ce8-f9520a90efea
# â• â•a1c4fc51-1878-4c13-8d01-3642d23ee670
# â•Ÿâ”€c10c7845-61ec-4275-b9a0-4934a7848e9b
# â• â•d70ac330-0aae-4fae-91a2-159f1c1bc11f
# â• â•44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
# â•Ÿâ”€32f8bc26-97e4-4cfa-b064-eebe0403accb
# â• â•dcc82e49-af10-4f9c-927d-1cf039a6185a
# â• â•86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
# â• â•6d1b48f9-c7c6-461d-9908-f2a36de2694f
# â•Ÿâ”€4c76d345-1d77-4f7f-9fbe-2d4707d70b29
# â•Ÿâ”€06e19a21-5a4e-48c0-9030-9c6c43a3afdb
# â•Ÿâ”€e3c46f60-b32e-4911-971f-230c87507f37
# â•Ÿâ”€0e168bfe-902b-4732-8ecb-a9a75b330bbb
# â• â•8ee75575-d2f2-409f-9016-dac048fc6ff6
# â•Ÿâ”€a21d65cb-d369-4e9b-a1a6-53b06b09dc22
# â• â•cb8d9a31-d415-45b7-a743-15c715dfd2a5
# â•Ÿâ”€8712e1ec-0b84-4fc4-a44e-6f5a91180b8b
# â• â•75d031cd-b55f-4d8a-89fd-3acb11a551ef
# â•Ÿâ”€1218bb53-fd4e-4574-ba62-e67f955ba0a8
# â• â•59c355a1-34d5-415b-9e29-afcab5103576
# â• â•7e9c42eb-c70f-4269-8b5e-b8cddbdc692b
# â• â•6300bcd6-44e4-4d2a-8e7d-dc7162eaea78
# â•Ÿâ”€fbd3a1ec-214f-450f-9c2e-547df22157d3
# â• â•55151073-083b-433c-96e0-5e51978e888f
# â•Ÿâ”€0250f930-ac62-4fdf-8e36-b79769974a25
# â• â•a012ef03-64a4-44cb-95c2-a5f734a3f75d
# â•Ÿâ”€12112daa-17f1-445a-93e8-131c35cfb53d
# â• â•10ab0262-00ef-4b77-8b6b-a43cf236a29d
# â•Ÿâ”€1ec6e447-fe94-4288-9996-0ba42c8d6cb0
# â• â•34f48c18-d452-4df4-a8f8-882bfc1db056
# â•Ÿâ”€2daa903b-af18-40ad-b9ce-0caf93b507c6
# â• â•afa08349-eab0-4ed6-a0aa-cc3cb39a619d
# â•Ÿâ”€bd1738fb-26f3-4ef8-a43c-f4c3740c46cb
# â• â•74f940f3-5c76-4f7e-a46a-12038d7584c7
