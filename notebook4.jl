### A Pluto.jl notebook ###
# v0.14.2

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : missing
        el
    end
end

# ‚ïî‚ïê‚ï° 32f6d41e-3248-4549-9546-53b34d5aa7c6
begin
	# instantiate environment
	using Pkg; Pkg.activate(@__DIR__); Pkg.instantiate()

	# load packages used in this notebook
	using GeoStats, MLJ
	using CSV, DataFrames
	using LossFunctions
	using Distributions
	using PlutoUI
	using Plots
	using StatsPlots

	# default plot settings
	gr(format=:png)
end;

# ‚ïî‚ïê‚ï° 762a6e04-fcb7-4713-859d-fdbfe8ead1bc
html"""
<p style="background-color:lightgrey" xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">GeoStats.jl at CBMina</span> by <span property="cc:attributionName">J√∫lio Hoffimann & Franco Naghetini</span> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>
"""

# ‚ïî‚ïê‚ï° 32429926-f6c3-44b8-b012-d2c67cad0b6d
md"""
![geostats-logo](https://github.com/JuliaEarth/GeoStats.jl/blob/master/docs/src/assets/logo-text.svg?raw=true)

# Geostat√≠stica moderna

Instrutores: [J√∫lio Hoffimann](https://juliohm.github.io) & [Franco Naghetini](https://github.com/fnaghetini)
"""

# ‚ïî‚ïê‚ï° 3c79e7aa-b316-4c4b-b44e-e73312085c20
md"""
## Aprendizado geoestat√≠stico

Neste m√≥dulo aprenderemos sobre esta nova √°rea denominada **aprendizado geoestat√≠stico** ([Hoffimann et al 2021](https://arxiv.org/abs/2102.08791)). Introduziremos os elementos do problema de aprendizado com **dados geoespaciais**, e veremos como a biblioteca [GeoStats.jl](https://github.com/JuliaEarth/GeoStats.jl) est√° na vanguarda desta tecnologia.

Existem quest√µes te√≥ricas muito interessantes que n√£o cobriremos neste minicurso, e que est√£o sendo desenvolvidas ativamente no projeto. Nos concentraremos aqui em **exemplos pr√°ticos** para que voc√™ possa adaptar este notebook aos seus pr√≥prios desafios na minera√ß√£o. Para mais detalhes te√≥ricos, assista o v√≠deo abaixo:
"""

# ‚ïî‚ïê‚ï° 4a3fb559-73dd-41e0-8a11-993e5bf286bf
html"""
<iframe width="560" height="315" src="https://www.youtube.com/embed/6S_9GLMv3xI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
"""

# ‚ïî‚ïê‚ï° f3ff120d-940c-40c9-b9f6-24d4a0b3aec1
md"""
Ao final deste m√≥dulo voc√™ ser√° capaz de:

- Identificar os **elementos do aprendizado geoestat√≠stico**
- Definir de forma clara **problemas de aprendizado na sua √°rea**
- Resolver o problema com **modelos geoespaciais do GeoStats.jl**

### Agenda

1. O que √© aprendizado de m√°quina?
2. A nova √°rea de **aprendizado geoestat√≠stico**
3. Os elementos do aprendizado geoestat√≠stico
4. Solu√ß√£o do problema (exemplo *Nova Zel√¢ndia*)
5. M√©todos de valida√ß√£o (sele√ß√£o de modelos)
"""

# ‚ïî‚ïê‚ï° 1856e01b-2d55-448d-8bdf-e59825934193
md"""
### 1. O que √© o aprendizado de m√°quina?

Antes de podermos entender o problema de aprendizado **geo**estat√≠stico, isto √©, o problema de aprendizado com dados **geoespacias**, precisamos entender o problema gen√©rico de **aprendizado de m√°quina** introduzido na ci√™ncia da computa√ß√£o na √°rea de **intelig√™ncia artificial**.

Nessa √°rea, buscam-se criar tecnologias capazes de "imitar" a intelig√™ncia humana. Ao inv√©s de tentarmos definir intelig√™ncia, vamos nos concentrar em duas habilidades que n√≥s humanos exercermos todo dia:

- A habilidade de **raciocinar sobre fatos**
- A habilidade **aprender com experi√™ncia**

#### Racioc√≠nio

A habilidade de **racioc√≠nio** √© o que nos permite gerar conclus√µes sobre fatos, segundo alguma l√≥gica pr√©-estabelecida. Essa habilidade pode ser entendida informalmente como um sistema dedutivo da forma:

$\text{premissa}_1 + \text{premissa}_2 + \cdots + \text{premissa}_n \longrightarrow \text{conclus√£o}$

onde um conjunto de **premissas** sobre o funcionamento do mundo leva a uma **conclus√£o** l√≥gica. Como exemplo, podemos considerar a habilidade de um ge√≥logo de deduzir condi√ß√µes mar√≠timas ao ver o f√≥ssil da Figura 2. O racioc√≠nio se d√° da seguinte forma:

- *Premissa 1:* Trilobitas s√£o seres marinhos
- *Premissa 2:* F√≥ssil de trilobita encontrado na regi√£o
- *Conclus√£o:* Regi√£o foi mar num passado distante
"""

# ‚ïî‚ïê‚ï° 615e4ed2-f77f-4f38-a6c1-7f0c0f985d49
html"""

<p align="center">

    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQLZzO7ZIjwJzgTPHk6EootRI5usLZCcuDJ-f0Vdz6aYq2rPpNFpaFM8FBPgny42fGfYQQ&usqp=CAU">

</p>

<p align="center">

    <b>Figura 1</b>: F√≥ssil de trilobita, um antr√≥pode do paleoz√≥ico de ambientes marinhos.

</p>

"""

# ‚ïî‚ïê‚ï° b89139a7-57da-4d9d-a791-c06edd5ab99d
md"""
Devemos observar que:

- Sistemas de racioc√≠nio determin√≠sticos como o exemplo acima tendem a falhar em √°reas da ci√™ncia que apresentam alta complexidade e intera√ß√£o entre as entidades envolvidas no racioc√≠nio, especialmente quando esses sistemas s√£o constru√≠dos por [seres humanos e seus v√°rios tra√ßos de irracionalidade](https://en.wikipedia.org/wiki/Predictably_Irrational).

- Sistemas de racioc√≠nio probabil√≠sticos, isto √©, sistemas que utilizam de teorias de probabilidade para representar incertezas no racioc√≠nio, tem sido mais bem sucedidos na ind√∫stria. Um exemplo deste tipo de sistema est√° descrito em [Hoffimann et al 2021. Probabilistic Knowledge-based Characterization of Conceptual Geological Models](https://www.sciencedirect.com/science/article/pii/S2590197421000033), onde um modelo conhecido como rede Bayesiana √© utilizado para auxiliar geocientistas na identifica√ß√£o de cen√°rios geol√≥gicos de um sistema petrol√≠fero (Figura 2).
"""

# ‚ïî‚ïê‚ï° 8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
html"""

<p align="center">

    <img src="https://ars.els-cdn.com/content/image/1-s2.0-S2590197421000033-gr1.jpg">

</p>

<p align="center">

    <b>Figura 2</b>: Modelo geol√≥gico conceitual e poss√≠veis cen√°rios geol√≥gicos para o sistema deposicional: Braided Rivers, Fluvial Delta, Continental Slope, Inner Shelf.

</p>

"""

# ‚ïî‚ïê‚ï° 301d2074-a2d7-44dc-aeb6-29e69ca5348f
md"""
> **Nota:** M√©todos de racioc√≠nio funcionam bem em problemas onde h√° um enorme acervo de conhecimento. S√£o √≥timos quando (1) poucos dados est√£o dispon√≠veis sobre um determinado objeto de estudo, e (2) a literatura √© irrefut√°vel.
"""

# ‚ïî‚ïê‚ï° a0b00451-7418-4d60-812f-5c2a9b32cd4d
md"""
#### Aprendizado

A habilidade de **aprendizado**, por outro lado, √© o que nos permite **gerar novas regras** sobre o ambiente em que operamos baseado em novas experi√™ncias vividas. √â com essa habilidade que evoluimos o nosso entendimento de mundo.

De forma mais precisa, podemos definir aprendizado em termos de experi√™ncia $\mathcal{E}$, tarefa $\mathcal{T}$ a ser executada e medida de performance $\mathcal{P}$ nessa tarefa. Adotaremos a defini√ß√£o do [Mitchell 1997](http://www.cs.cmu.edu/~tom/mlbook.html):

**Defini√ß√£o (Aprendizado).** *Dizemos que um agente (e.g. programa de computador) aprende com a experi√™ncia $\mathcal{E}$ em relac√£o √† tarefa $\mathcal{T}$ e √† medida de performance $\mathcal{P}$ se a performance, medida por $\mathcal{P}$, melhora com a experi√™ncia $\mathcal{E}$.*

Por exemplo, um programa de computador pode aprender a jogar xadrez jogando partidas contra si mesmo. A medida de performance pode ser o n√∫mero de partidas ganhas em um s√©rie de 10 partidas, e nesse caso cada partida √© uma experi√™ncia nova adquirida.

Aqui estamos interessados no **aprendizado estat√≠stico** que consiste de aprender novas regras utilizando grandes bases de dados como furos de sondagem, dados oriundos da geometalurgia, e imagens de sat√©lite. Em particular, estamos interessados na aplicac√£o dessa teoria por meio de programas de computador, conhecida como **aprendizado de m√°quina** (em ingl√™s "machine learning" ou "ML").

A teoria de aprendizado estat√≠stico est√° por tr√°s de diversas tecnologias atuais, especialmente o **aprendizado estat√≠stico supervisionado** que consiste em aprender uma fun√ß√£o *desconhecida* $f\colon x \mapsto y$ por meio de v√°rios exemplos $\left\{(x_1,y_1), (x_2,y_2),\ldots,(x_n,y_n)\right\}$ de entrada e sa√≠da da fun√ß√£o:
"""

# ‚ïî‚ïê‚ï° 29cf81d4-996e-4283-8d72-63d3ed1f55a7
md"""
T: $(@bind T Slider(0.1:0.1:1, default=0.3, show_value=true))

n: $(@bind n Slider(100:100:500, show_value=true))
"""

# ‚ïî‚ïê‚ï° f4ad710d-f2a0-4110-8e6f-d76f181881ae
f(x) = sin(x / T)

# ‚ïî‚ïê‚ï° fc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
begin
	xs = rand(Normal(), n)
	ys = f.(xs) .+ rand(Normal(0,0.1), n)
	
	plot(f, -1, 1, color = :green, label = "f(x)",
		 xlims = (-1, 1), ylims = (-1, 1),
		 xlabel = "x", ylabel = "y",
	     title = "Como aprender f(x)?")
	scatter!([(x, -1) for x in xs], label = "x‚ÇÅ, x‚ÇÇ, ..., x‚Çô",
	         marker = (:spike, 10, :black))
	scatter!(collect(zip(xs, ys)), label = "y‚ÇÅ, y‚ÇÇ, ..., y‚Çô",
	         marker = (:circle, 3, :black))
end

# ‚ïî‚ïê‚ï° 6f400014-4f12-42ec-8ee8-db181d82f656
md"""
Quanto mais complexa √© a fun√ß√£o $f$, mais exemplos s√£o necess√°rios para aprend√™-la segundo alguma medida de performance (e.g. erro quadr√°tico). Por exemplo, se o per√≠odo de oscila√ß√£o $T / 2\pi$ da fun√ß√£o acima for baixo, mais densa ter√° que ser a amostragem do eixo $x$ para um aprendizado bem sucedido.

Observamos que:

- O eixo $x$ no aprendizado cl√°ssico representa uma **propriedade ou caracter√≠stica** do exemplo. Por exemplo, o m√≥dulo de Young ou o teor de um certo min√©rio numa amostra.
- O eixo $y$ representa uma **propriedade que se quer prever**, e que est√° relacionada de alguma forma com a propriedade $x$.
"""

# ‚ïî‚ïê‚ï° a280a283-59c3-4728-9110-b91d5ea63568
md"""
> **Nota:** M√©todos de aprendizado estat√≠stico funcionam bem em problemas onde h√° uma grande quantidade de dados (os exemplos), preferencialmente anotados por especialistas.
"""

# ‚ïî‚ïê‚ï° bfdbec36-069d-422d-8f88-fd97f8d85455
md"""
### 2. Aprendizado geoestat√≠stico

A **teoria de aprendizado cl√°ssica** utilizada no desenvolvimento de v√°rios m√©todos de aprendizado de m√°quina **n√£o √© apropriada para lidar com dados geoespaciais**, principalmente porque a maior parte da literatura assume que:

1. A distribui√ß√£o das propriedades dos exemplos √© fixa.
2. Os exemplos  s√£o independentes e identicamente distribu√≠dos (I.I.D.).
3. Os exemplos tem um suporte amostral (ou volume f√≠sico) comum.

Recentemente, n√≥s formalizamos o problema de **aprendizado geoestat√≠stico** (em ingl√™s "geostatistical learning" ou "GL") com o intuito de resolver grandes desafios de aprendizado de m√°quina com dados geoespaciais. [Hoffimann et al 2021. Geostatistical Learning: Challenges and Opportunities](https://arxiv.org/abs/2102.08791).

Para ilustrar esses desafios, vamos considerar um conjunto de dados de po√ßos de petr√≥leo que constru√≠mos de fontes p√∫blicas da Nova Zel√¢ndia ([Carvalho et al. 2020](https://zenodo.org/record/3832955#.YHmR9EOYU3w)):
"""

# ‚ïî‚ïê‚ï° b6b9f6db-5d69-496b-9862-bf7d6add901b
table = CSV.File("data/taranaki/logs.csv") |> DataFrame

# ‚ïî‚ïê‚ï° 2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
md"""
e uma tarefa de aprendizado que consiste em prever o tipo de forma√ß√£o da rocha ($y$ = `FORMATION`) em po√ßos `OFFSHORE` como fun√ß√£o de perfis (ou "logs") eletromagn√©ticos ($x$ = (`GR`, `SP`, ...)) e com base em anota√ß√µes $y_i = f(x_i)$ feitas por especialistas em po√ßos `ONSHORE` de mais f√°cil acesso.
"""

# ‚ïî‚ïê‚ï° c2fbca00-a248-4f9e-9754-08fd47225bed
md"""
#### Falsifica√ß√£o da hip√≥tese 1

Por simplicidade, eliminaremos as linhas da tabela com dados faltantes para os logs `GR`, `SP`, `DENS`, `NEUT` e `DTC`, e manteremos apenas as linhas com forma√ß√µes `Manganui` e `Urenui`.

Para facilitar a interpreta√ß√£o dos dados e o posterior treinamento de modelos de aprendizado, n√≥s normalizaremos os logs para que tenham m√©dia zero e desvio padr√£o unit√°rio.
"""

# ‚ïî‚ïê‚ï° b106e967-13c3-483d-bc53-9772c25947be
begin
	# Dados utilizados no experimento
	LOGS  = [:GR,:SP,:DENS,:NEUT,:DTC]
	CATEG = [:FORMATION, :ONSHORE]
	COORD = [:X, :Y, :Z]
	FORMS = ["Manganui", "Urenui"]
	
	# Opera√ß√µes de pr√©-processamento
	f1(table) = select(table, [LOGS; CATEG; COORD])
	
	f2(table) = dropmissing(table)
	
	f3(table) = filter(row -> row.FORMATION ‚àà FORMS, table)
	
	function f4(table)
		result = copy(table)
		for LOG in LOGS
			x = table[!, LOG]
			
			Œº = mean(x)
			œÉ = std(x, mean = Œº)
	
			result[!, LOG] = (x .- Œº) ./ œÉ
		end
		result
	end
	
	# Execu√ß√£o das opera√ß√µes em sequ√™ncia
	samples = table |> f1 |> f2 |> f3 |> f4
end

# ‚ïî‚ïê‚ï° e912de0f-cab2-4e11-b0bd-6a9603a9e966
describe(samples)

# ‚ïî‚ïê‚ï° ce132078-cfd3-4455-98b4-3297b1be405f
md"""
Como a tarefa de aprendizado que definimos consiste em prever a forma√ß√£o em po√ßos `OFFSHORE` baseado em anota√ß√µes em po√ßos `ONSHORE`, n√≥s visualizaremos os dados agrupados dessa forma. Em particular, n√≥s queremos investigar a **distribui√ß√£o bivariada** entre o logs $(@bind X1 Select(string.(LOGS))) e $(@bind X2 Select(string.(LOGS), default="SP")) nesse agrupamento:
"""

# ‚ïî‚ïê‚ï° 4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
begin
	# Agrupamento em pocos onshore and offshore
	G1, G2 = DataFrames.groupby(samples, :ONSHORE)
	
	T1 = G1.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	T2 = G2.ONSHORE[1] ? "ONSHORE" : "OFFSHORE"
	
	p1 = scatter(G1[!,X1], G1[!,X2], marker = (:gray, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T1)
	p2 = scatter(G2[!,X1], G2[!,X2], marker = (:purple, 1),
		         xlabel = X1, ylabel = X2, legend = false, title = T2)
	
	plot(p1, p2, link = :both, aspect_ratio = :equal, size = (700, 400))
end

# ‚ïî‚ïê‚ï° 4eadc228-7905-4328-ab01-f21339dd40aa
md"""
Da visualiza√ß√£o concluimos que a hip√≥tese (1) da teoria cl√°ssica n√£o √© v√°lida neste caso. Isto √©, a **distribui√ß√£o das propriedades dos exemplos varia drasticamente** de um dom√≠nio geoespacial para outro, mesmo quando consideramos um subconjunto pequeno dos dados para duas forma√ß√µes localizadas em uma √∫nica bacia.
"""

# ‚ïî‚ïê‚ï° 3855a6d5-7b8a-487b-abad-288f9fc0152d
md"""
#### Falsifica√ß√£o da hip√≥tese 2

Vejamos agora a hip√≥tese (2) da teoria cl√°ssica que assume que exemplos utilizados no treinamento de um modelo de aprendizado s√£o amostrados de forma independente no espa√ßo de propriedades.

Para avaliarmos essa hip√≥tese, utilizaremos a **an√°lise variogr√°fica**. O GeoStats.jl possui estimadores de variogramas de alta performance que conseguem lidar com **centenas de milhares** de amostras em poucos segundos. [Hoffimann & Zadrozny. 2019. Efficient variography with partition variograms.](https://www.sciencedirect.com/science/article/pii/S0098300419302936).

Para utilizar esses estimadores, n√≥s precisaremos **georreferenciar a tabela** de amostras em um dado geoespacial do GeoStats.jl que chamamos de `GeoData`. Esse dado se comporta como uma tabela comum, mas adicionalmente armazena informa√ß√µes necess√°rias para an√°lises geoespaciais.

Al√©m de georreferenciar as amostras, n√≥s iremos aproveitar esta etapa de processamento para especificar o **tipo cient√≠fico** de cada coluna da tabela. Por padr√£o esses tipos s√£o inferidos pela linguagem como:
"""

# ‚ïî‚ïê‚ï° eb9d3014-65b2-44f7-8d33-445826e6974b
schema(samples)

# ‚ïî‚ïê‚ï° 4b41d46e-ccf0-4232-8ce8-f9520a90efea
md"""
N√≥s iremos converter os tipos cient√≠ficos `Textual` e `Count` das colunas `FORMATION` e `ONSHORE` pelo tipo `Multiclass` que representa uma propriedade categ√≥rica.

Por fim, n√≥s iremos agregar todas as amostras com coordenadas repetidas em uma √∫nica amostra j√° que procedimentos de variografia requerem unicidade de coordenadas no conjunto de dados.

Em resumo, n√≥s utilizaremos:

1. A fun√ß√£o `coerce` para especificar o tipo cient√≠fico das colunas `FORMATION` e `ONSHORE`.
2. A fun√ß√£o `georef` para georreferenciar as amostras utilizando as coordenadas `X`, `Y` e `Z`.
3. A fun√ß√£o `uniquecoords` para eliminar amostras com coordenadas repetidas.
"""

# ‚ïî‚ïê‚ï° a1c4fc51-1878-4c13-8d01-3642d23ee670
begin
	# Opera√ß√µes de pr√©-processamento
	g1(table) = coerce(table, :FORMATION => Multiclass, :ONSHORE => Multiclass)
	
	g2(table) = georef(table, (:X, :Y, :Z))
	
	g3(table) = uniquecoords(table)
	
	# Execu√ß√£o das opera√ß√µes em sequ√™ncia
	ùíÆ = samples |> g1 |> g2 |> g3 |> GeoData
end

# ‚ïî‚ïê‚ï° c10c7845-61ec-4275-b9a0-4934a7848e9b
md"""
Para avaliar a depend√™ncia das amostras, calculamos o variograma direcional (vertical) ao longo da dire√ß√£o dos po√ßos para qualquer uma das vari√°veis:
"""

# ‚ïî‚ïê‚ï° d70ac330-0aae-4fae-91a2-159f1c1bc11f
Œ≥ = DirectionalVariogram((0.,0.,1.), ùíÆ, :GR, maxlag = 100., nlags = 50, dtol = 10.)

# ‚ïî‚ïê‚ï° 44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
plot(Œ≥)

# ‚ïî‚ïê‚ï° 32f8bc26-97e4-4cfa-b064-eebe0403accb
md"""
O comprimento de correla√ß√£o ou "range" positivo do variograma indica a depend√™ncia espacial das amostras, e pode ser estimado por m√≠nimos quadrados ponderados:
"""

# ‚ïî‚ïê‚ï° dcc82e49-af10-4f9c-927d-1cf039a6185a
Œ≥‚Çú = fit(Variogram, Œ≥, h -> exp(-h/20))

# ‚ïî‚ïê‚ï° 86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
r = range(Œ≥‚Çú)

# ‚ïî‚ïê‚ï° 6d1b48f9-c7c6-461d-9908-f2a36de2694f
plot(Œ≥); plot!(Œ≥‚Çú, 0, 100)

# ‚ïî‚ïê‚ï° 4c76d345-1d77-4f7f-9fbe-2d4707d70b29
md"""
A partir da an√°lise variogr√°fica, concluimos que a hip√≥tese (2) tamb√©m n√£o √© valida neste caso. As amostras s√£o adjacentes no espa√ßo f√≠sico, e est√£o mais pr√≥ximas entre si do que o comprimento de correla√ß√£o do processo. Ou seja, as **amostras est√£o associadas geoespacialmente**.
"""

# ‚ïî‚ïê‚ï° 06e19a21-5a4e-48c0-9030-9c6c43a3afdb
md"""
#### Falsifica√ß√£o da hip√≥tese 3

A hip√≥tese (3) n√£o √© valida, pois como discutimos no primeiro dia do minicurso, amostras geof√≠sicas geralmente tem um suporte (ou volume f√≠sico) vari√°vel. Neste caso, **o espa√ßamento das amostras ao longo dos po√ßos n√£o √© constante**.
"""

# ‚ïî‚ïê‚ï° e3c46f60-b32e-4911-971f-230c87507f37
md"""
#### Resumo

- A **an√°lise bivariada** indicou que as **distribui√ß√µes das propriedades** em po√ßos `ONSHORE` e `OFFSHORE` **s√£o distintas**. Portanto, n√£o √© aconselh√°vel treinar um modelo de aprendizado com anota√ß√µes em po√ßos `ONSHORE` e aplic√°-lo diretamente a po√ßos `OFFSHORE`, e vice versa.

- A **an√°lise variogr√°fica** indicou a **exist√™ncia de correla√ß√£o linear** ao longo dos po√ßos. Isso significa que modelos de aprendizado cl√°ssicos desenvolvidos assumindo independ√™ncia de exemplos podem apresentar, e geralmente apresentam, deteriora√ß√£o de performance em aplica√ß√µes pr√°ticas em geoci√™ncias.

Precisamos de uma nova defini√ß√£o de aprendizado com dados geoespaciais, que chamaremos de **aprendizado geoestat√≠stico** ou GL:

**Defini√ß√£o (GL).** *Dado um dom√≠nio geoespacial de origem $\mathcal{D}_s$ (ou "source") e uma tarefa de aprendizado $\mathcal{T}_s$, e um dom√≠nio de destino $\mathcal{D}_t$ (ou "target") e uma tarefa de aprendizado $\mathcal{T}_t$. O aprendizado geoestat√≠stico consiste em aprender a tarefa $\mathcal{T}_t$ no dom√≠nio $\mathcal{D}_t$ utilizando o conhecimento adquirido no aprendizado da tarefa $\mathcal{T}_s$ no dom√≠nio $\mathcal{D}_s$. Assumindo que as propriedades em $\mathcal{D}_s$ e $\mathcal{D}_t$ s√£o uma √∫nica realiza√ß√£o dos processos envolvidos.*
"""

# ‚ïî‚ïê‚ï° 0e168bfe-902b-4732-8ecb-a9a75b330bbb
md"""
### 3. Elementos do aprendizado geoestat√≠stico

Para esclarecer a defini√ß√£o de GL, continuaremos explorando os dados da Nova Zel√¢ndia.

#### Dom√≠nio geoespacial

O primeiro elemento da defini√ß√£o √© o **dom√≠nio geoespacial** onde os dados est√£o georreferenciados:

- O **dom√≠nio de origem** $\mathcal{D}_s$ representa as trajet√≥rias dos po√ßos `ONSHORE`. Nesse dom√≠nio est√£o dispon√≠veis os logs, assim como as anota√ß√µes do tipo de forma√ß√£o feitas por especialistas.
- O **dom√≠nio de destino** $\mathcal{D}_t$ representa as trajet√≥rias dos po√ßos `OFFSHORE`. Nesse dom√≠nio est√£o dispon√≠veis apenas os logs que ser√£o utilizados pelo modelo de aprendizao para previs√£o do tipo de forma√ß√£o.
"""

# ‚ïî‚ïê‚ï° bfbb10f9-364f-441a-872a-96753c3d2231
html"""

<p align="center">

    <img src="https://i.postimg.cc/d3BpsStQ/domains.png">

</p>

<p align="center">

    <b>Figura 3</b>: Dom√≠nio geoespacial de origem e de destino.

</p>

"""

# ‚ïî‚ïê‚ï° 89e8f272-8812-4e1e-8ab6-1cb7700c0fde
md"""
Vemos que os nossos dados geoespaciais est√£o definidos em um dom√≠nio do tipo `PointSet`:
"""

# ‚ïî‚ïê‚ï° 8ee75575-d2f2-409f-9016-dac048fc6ff6
domain(ùíÆ)

# ‚ïî‚ïê‚ï° a21d65cb-d369-4e9b-a1a6-53b06b09dc22
md"""
E que a tabela de valores associada a esse dom√≠nio cont√©m as seguintes vari√°veis:
"""

# ‚ïî‚ïê‚ï° cb8d9a31-d415-45b7-a743-15c715dfd2a5
values(ùíÆ) |> DataFrame

# ‚ïî‚ïê‚ï° 8712e1ec-0b84-4fc4-a44e-6f5a91180b8b
md"""
Queremos particionar os dados em po√ßos `ONSHORE` e `OFFSHORE` de acordo com a informa√ß√£o j√° presente na tabela de valores. Utilizaremos a fun√ß√£o `groupby` do GeoStats.jl para **particionar os dados preservando as informa√ß√µes geoespaciais**. O resultado da parti√ß√£o possui um campo de metadados associados a cada subconjunto que podemos utilizar para definir os dois dom√≠nios de interesse:
"""

# ‚ïî‚ïê‚ï° 59c355a1-34d5-415b-9e29-afcab5103576
function onandoff(ùíÆ)
	Œ† = GeoStats.groupby(ùíÆ, :ONSHORE)
	
	ON‚ÇÅ, ON‚ÇÇ = metadata(Œ†)[:values]
	
	if ON‚ÇÅ == true
		ùíÆ‚Çõ, ùíÆ‚Çú = Œ†
	else
		ùíÆ‚Çú, ùíÆ‚Çõ = Œ†
	end
end

# ‚ïî‚ïê‚ï° 340c939a-2a9b-475d-91ef-62effb2a8da3
ùíÆ‚Çõ, ùíÆ‚Çú = onandoff(ùíÆ)

# ‚ïî‚ïê‚ï° 2c7442fa-5b8c-411d-b3f8-f0ed2ed00dc8
md"""
Para evitar vi√©s no processo de aprendizado, n√≥s balancearemos os dados utilizando uma simples t√©cnica de **subamostragem**. Essa t√©cnica reduz a presen√ßa da forma√ß√£o majorit√°ria no treinamento de modelos estat√≠sticos, e √© adequada para grandes conjuntos de dados.

Ao aplicar a subamostragem nos po√ßos `ONSHORE` e `OFFSHORE` obtemos um novo conjunto de dados balanceado com 50% dos exemplos na forma√ß√£o `Manganui` e 50% na forma√ß√£o `Urenui`:
"""

# ‚ïî‚ïê‚ï° a7b23e9e-b3f3-4a8b-a5a7-dae05fd73bf1
function balance(ùíÆ)
	# Coluna com anota√ß√µes
	y  = ùíÆ[:FORMATION]
	
	# Localiza√ß√µes na forma√ß√£o Manganui
	y‚ÇÅ = isequal.(y, "Manganui")
	
	# Contagem de exemplos nas duas forma√ß√µes
	n  = length(y)
	n‚ÇÅ = count(y‚ÇÅ)
	n‚ÇÇ = n - n‚ÇÅ
	
	# Subamostragem dos dados
	if n‚ÇÅ > n‚ÇÇ
		inds‚ÇÅ = sample(findall(y‚ÇÅ), n‚ÇÇ, replace = false)
		inds‚ÇÇ = findall(!, y‚ÇÅ)
	else
		inds‚ÇÅ = findall(y‚ÇÅ)
		inds‚ÇÇ = sample(findall(!, y‚ÇÅ), n‚ÇÅ, replace = false)
	end
	
	view(ùíÆ, [inds‚ÇÅ; inds‚ÇÇ])
end

# ‚ïî‚ïê‚ï° 777f4131-2cbb-4ba5-b786-d6175e3036a5
Œ©‚Çõ, Œ©‚Çú = balance(ùíÆ‚Çõ), balance(ùíÆ‚Çú)

# ‚ïî‚ïê‚ï° fbd3a1ec-214f-450f-9c2e-547df22157d3
md"""
#### Tarefa de aprendizado

O segundo elemento da defini√ß√£o √© a **tarefa de apendizado**. Neste caso, definimos uma √∫nica tarefa de previs√£o de forma√ß√£o a partir de logs, ou seja $\mathcal{T}_s = \mathcal{T}_t$. No jarg√£o de aprendizado essa tarefa √© uma tarefa de classifica√ß√£o:
"""

# ‚ïî‚ïê‚ï° 55151073-083b-433c-96e0-5e51978e888f
ùíØ = ClassificationTask(LOGS, :FORMATION)

# ‚ïî‚ïê‚ï° 0250f930-ac62-4fdf-8e36-b79769974a25
md"""
Com isso podemos definir o nosso problema de aprendizado geoestat√≠stico:
"""

# ‚ïî‚ïê‚ï° a012ef03-64a4-44cb-95c2-a5f734a3f75d
problem = LearningProblem(Œ©‚Çõ, Œ©‚Çú, ùíØ)

# ‚ïî‚ïê‚ï° 12112daa-17f1-445a-93e8-131c35cfb53d
md"""
Como veremos em seguida, n√≥s podemos resolver o problema com mais de **150** modelos de aprendizado dispon√≠veis no projeto [MLJ.jl](https://github.com/alan-turing-institute/MLJ.jl), incluindo todos os modelos do [scikit-learn](https://scikit-learn.org) e outros modelos de alta performance implementados em Julia:
"""

# ‚ïî‚ïê‚ï° 10ab0262-00ef-4b77-8b6b-a43cf236a29d
models() |> DataFrame

# ‚ïî‚ïê‚ï° 427d35b8-daf0-4d16-87e5-f8eb33e265fe
md"""
> **Nota:** √â extremamente importante separar a **defini√ß√£o do problema** de aprendizado geostat√≠stico da **estrat√©gia de solu√ß√£o** para uma compara√ß√£o justa de modelos. A maioria dos frameworks cl√°ssicos de aprendizado (e.g. scikit-learn) **n√£o** permite essa separa√ß√£o.
"""

# ‚ïî‚ïê‚ï° 1ec6e447-fe94-4288-9996-0ba42c8d6cb0
md"""
### 4. Solu√ß√£o do problema

#### Modelos de aprendizado

Com o problema de aprendizado geoestat√≠stico bem definido, n√≥s podemos investigar diferentes estrat√©gias de solu√ß√£o e realizar valida√ß√µes avan√ßadas que s√≥ est√£o dispon√≠veis no GeoStats.jl.

Primeiro n√≥s precisamos definir uma lista de modelos de aprendizado para resolver o problema. Estamos interessados em modelos:

1. **Implementados em Julia** por terem uma maior performance computacional.
2. Adequados para a tarefa de **classifica√ß√£o de forma√ß√£o** definida no problema:
    - Modelos **supervisionados** (que aprendem de exemplos de entrada e sa√≠da)
    - Com **vari√°vel alvo bin√°ria** (que produzem previs√µes `Manganui` ou `Urenui`)
3. Sob licen√ßa **MIT** por ser uma licen√ßa de c√≥digo aberto permiss√≠vel.

Podemos encontrar esses modelos utilizando filtros na fun√ß√£o `models`:
"""

# ‚ïî‚ïê‚ï° 34f48c18-d452-4df4-a8f8-882bfc1db056
models(m -> m.is_pure_julia && m.is_supervised &&
	        m.target_scitype >: AbstractVector{<:Multiclass{2}} &&
	        m.package_license == "MIT") |> DataFrame

# ‚ïî‚ïê‚ï° 2daa903b-af18-40ad-b9ce-0caf93b507c6
md"""
Utilizaremos os seguintes modelos:
"""

# ‚ïî‚ïê‚ï° afa08349-eab0-4ed6-a0aa-cc3cb39a619d
begin
	‚Ñ≥‚ÇÅ = @load DecisionTreeClassifier pkg = DecisionTree
	‚Ñ≥‚ÇÇ = @load KNNClassifier          pkg = NearestNeighborModels
	‚Ñ≥‚ÇÉ = @load LogisticClassifier     pkg = MLJLinearModels
	‚Ñ≥‚ÇÑ = @load ConstantClassifier     pkg = MLJModels
	
	‚Ñ≥s = [‚Ñ≥‚ÇÅ(), ‚Ñ≥‚ÇÇ(), ‚Ñ≥‚ÇÉ(), ‚Ñ≥‚ÇÑ()]
end

# ‚ïî‚ïê‚ï° b0843d5b-69eb-4a53-bff7-2d3bbd8b0057
md"""
#### Estrat√©gia de solu√ß√£o

Para que os modelos de aprendizado possam ser utilizados com dados geoespaciais no GeoStats.jl, n√≥s precisamos definir uma **estrat√©gia de solu√ß√£o**. A estrat√©gia de solu√ß√£o mais comum na literatura geoespacial √© o que denominamos aprendizado ponto-a-ponto (em ingl√™s "pointwise learning"):
"""

# ‚ïî‚ïê‚ï° 9dd85a75-c1e3-418a-bb3e-7c8875e9c5dd
solvers = [PointwiseLearn(‚Ñ≥) for ‚Ñ≥ in ‚Ñ≥s];

# ‚ïî‚ïê‚ï° bd82b213-99b2-4ba7-997c-9ddbac69579c
md"""
Essa estrat√©gia simplesmente **ignora as coordenadas** dos exemplos e trata o dado geoespacial como uma **tabela comum**. Apesar de ser uma estrat√©gia simplista, ela pode demandar bastante tempo do usu√°rio final que fica respons√°vel pelo pr√©- e p√≥s-processamento dos dados em formatos tabulares.

O GeoStats.jl **automatiza esse processo de convers√£o** e salva tempo do geocientista interessado em testar diferentes modelos. Em particular, o framework se encarrega de:

1. Treinar o modelo encapsulado no dom√≠nio geoespacial de origem
2. Aplicar o modelo treinado no dom√≠nio geoespacial de destino

onde os dom√≠nios geoespaciais podem ser **qualquer tipo de malha** do projeto [Meshes.jl](https://github.com/JuliaGeometry/Meshes.jl).
"""

# ‚ïî‚ïê‚ï° 3ba896bd-e569-40c3-9fa1-3e79db50bf45
solutions = [solve(problem, solver) for solver in solvers]

# ‚ïî‚ïê‚ï° f66e960b-e38f-4414-be79-09658eb5cf74
md"""
#### Avalia√ß√£o qualitativa

Podemos facilmente visualizar qualquer uma das solu√ß√µes obtidas. Como o n√∫mero de amostras √© consider√°vel neste caso, e n√£o estamos utilizando o [Makie.jl](https://github.com/JuliaPlots/Makie.jl) para visualiza√ß√µes 3D, visualizaremos apenas um subconjunto da soluc√£o i = $(@bind i Scrubbable(1:length(solvers), default=1)):
"""

# ‚ïî‚ïê‚ï° b70f5ab7-9790-4daf-a881-d75c602aaa67
solution·µ¢ = sample(solutions[i], 10000, replace = false);

# ‚ïî‚ïê‚ï° 5ec99dcc-58b4-4290-8f05-884ef11e464d
plot(solution·µ¢, marker = (:BrBG_3, 4), colorbar = false,
	 xlabel = "X", ylabel = "Y", zlabel = "Z",
	 title = "PREVIS√ÉO DE FORMA√á√ÉO\n(Manganui = Laranja, Urenui = Verde)")

# ‚ïî‚ïê‚ï° 78d9f9ba-1947-4bec-bc74-b895d084365e
md"""
#### Avalia√ß√£o quantitativa

Como neste **caso sint√©tico** n√≥s temos acesso ao tipo de forma√ß√£o nos po√ßos `OFFSHORE`, n√≥s podemos quantificar o erro de cada modelo utilizado.

Em problemas de classifica√ß√£o, √© comum reportar a **matriz de confus√£o** para cada modelo. Essa matriz informa o n√∫mero de vezes que uma forma√ß√£o (coluna da matriz) foi classificada pelo modelo como uma certa outra forma√ß√£o (linha da matriz):
"""

# ‚ïî‚ïê‚ï° e6e84f8b-e132-42a7-a0e4-1acd9006dbbb
map(solutions) do Œ©ÃÇ·µ¢
	# Previs√£o da forma√ß√£o
	yÃÇ = Œ©ÃÇ·µ¢[:FORMATION]
	
	# Valor real da forma√ß√£o
	y = Œ©‚Çú[:FORMATION]
	
	# Matriz de confus√£o
    confmat(yÃÇ, y)
end

# ‚ïî‚ïê‚ï° 653ed159-838c-47d6-878e-0b2530cf7c52
md"""
Observamos que:

- O **modelo mais simples** (logistic) apresenta os **melhores resultados** nos po√ßos `OFFSHORE`.
- Os **modelos mais complexos** (e.g. decision tree, knn) ficam **"superfitados"** aos po√ßos `ONSHORE` devido principalmente a diferen√ßa de distribui√ß√£o `ONSHORE` e `OFFSHORE`.
- O modelo constante apresenta o pior resultado como esperado.

Podemos sumarizar a informa√ß√£o da matriz de confus√£o com diferentes medidas, como por exemplo a medida $F_1$-score. A medida √© bastante utilizada na √°rea m√©dica, e √© calculada como

$F_1 = \frac{tp}{tp + \frac{fp + fn}{2}}$

onde $tp$ √© o n√∫mero de verdadeiros positivos, $fp$ √© o n√∫mero de falsos positivos, e $fn$ √© o n√∫mero de falsos negativos. Em geral quanto maior √© o $F_1$-score, maior √© a performance do modelo:
"""

# ‚ïî‚ïê‚ï° da350067-a8fb-47bc-b9b8-b069e742383b
html"""

<p align="center">

    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png">

</p>

<p align="center">

    <b>Figura 4</b>: Ilustra√ß√£o da medida F1-score como combina√ß√£o de precis√£o e recall.

</p>

"""

# ‚ïî‚ïê‚ï° ab970650-8dbd-442b-9a25-4cd871ecd336
map(solutions) do Œ©ÃÇ·µ¢
	# Previs√£o da forma√ß√£o
	yÃÇ = Œ©ÃÇ·µ¢[:FORMATION]
	
	# Valor real da forma√ß√£o
	y = Œ©‚Çú[:FORMATION]
	
	# Matriz de confus√£o
	f1score(yÃÇ, y)
end

# ‚ïî‚ïê‚ï° 3e469cb8-745d-4f11-a6e7-814f29e1ccef
md"""
Dessa forma, se soub√©ssemos o valor real da forma√ß√£o nos po√ßos `OFFSHORE`, n√≥s poder√≠amos escolher o modelo logistic como o melhor modelo segundo o $F_1$-score. Na pr√°tica, por√©m, **n√£o temos as anota√ß√µes no dom√≠nio geoespacial de destino**, e precisamos de outras m√©todos para a sele√ß√£o de modelos.

Antes de investigarmos esses m√©todos em detalhe na pr√≥xima se√ß√£o, observamos que existem mais de **50** medidas dispon√≠veis para avaliar modelos de aprendizado quando as anota√ß√µes s√£o conhecidas em um caso sint√©tico. Podemos utilizar a fun√ß√£o `measures` para descobrir as medidas v√°lidas para as solu√ß√µes encontradas:
"""

# ‚ïî‚ïê‚ï° 5b54c097-07b2-4c26-85b1-c7716cd98145
measures(s -> s.target_scitype >: AbstractVector{<:Multiclass{2}} &&
	          s.prediction_type == :deterministic) |> DataFrame

# ‚ïî‚ïê‚ï° 7d6597a0-ae24-483a-a67f-dd6235acb25e
md"""
### 5. Valida√ß√£o cruzada

Nas se√ß√µes anteriores, aprendemos a definir um problema de aprendizado geoestat√≠stico e a resolver esse problema com diferentes modelos. Nesta se√ß√£o aprenderemos a selecionar modelos mesmo quando as anota√ß√µes dos especialistas n√£o est√£o dispon√≠veis no dom√≠nio geoespacial de destino.

Dentre os v√°rios m√©todos de sele√ß√£o, os m√©todos de **valida√ß√£o cruzada** s√£o os que apresentam os resultados mais satisfat√≥rios em problemas reais. Esses m√©todos se baseiam nas seguintes observa√ß√µes:

1. Anota√ß√µes de especialistas s√≥ est√£o dispon√≠veis no dom√≠nio geoespacial de origem $\mathcal{D}_s$.
2. Subconjuntos de dados em $\mathcal{D}_s$ podem apresentar a mesma distribui√ß√£o dos dados originais.
3. √â poss√≠vel treinar um modelo em um subdom√≠nio $\mathcal{B}_s \subset \mathcal{D}_s$ e avaliar em $\mathcal{D}_s - \mathcal{B}_s$.

A Figure 4 ilustra um processo de subdivis√£o do dom√≠nio de origem em subdom√≠nios aleat√≥rios marcados em cores distintas. Esse subdom√≠nios s√£o chamados de **folds**.
"""

# ‚ïî‚ïê‚ï° d10b3695-0f6d-406f-813d-17e76d47ba76
html"""

<p align="center">

    <img src="https://i.postimg.cc/wj642dcw/cv.png">

</p>

<p align="center">

    <b>Figura 5</b>: Folds aleat√≥rios no dom√≠nio geoespacial de origem representados em diferentes cores.

</p>

"""

# ‚ïî‚ïê‚ï° f96d976f-f40c-4ad2-8bbe-e45da5a3ae3d
md"""
O processo de valida√ß√£o cruzada consiste em **omitir** um dos $k$ folds do conjunto de dados, **treinar** o modelo nos $k-1$ folds restantes, e **avaliar** quantitativamente o erro do modelo no fold que foi omitido. Esse processo √© repitido para todos os folds ou cores do dom√≠nio, e os resultados s√£o agregados em um erro esperado:

$\epsilon(m) = \frac{1}{k} \sum_{i=1}^k \sum_{j=1}^{n_k} w^{(i)}_j \cdot \mathcal{L}(\hat{y}^{(i)}_j, y^{(i)}_j)$

onde $m$ √© o modelo sendo avaliado, $\mathcal{L}$ √© uma fun√ß√£o conhecida como **fun√ß√£o de perda**, e $w^{(i)}_j$ √© um peso atribu√≠do ao erro do exemplo $j$ no fold $i$.

Revisaremos tr√™s m√©todos de valida√ß√£o cruzada:

1. Valida√ß√£o cruzada cl√°ssica (CV)
2. Valida√ß√£o cruzada em blocos (BCV)
4. Valida√ß√£o cruzada com raz√£o de densidade (DRV)
"""

# ‚ïî‚ïê‚ï° 6ccd3492-a71d-4848-97e1-900614df7aa7
md"""
#### Valida√ß√£o cruzada cl√°ssica (CV)

A valida√ß√£o cruzada cl√°ssica √© o m√©todo mais simples de valida√ß√£o no qual os **folds s√£o aleat√≥rios** e todos os exemplos recebem o mesmo **peso unit√°rio** (Figura 5). Por ser bastante simples, o m√©todo est√° dispon√≠vel em qualquer framework de aprendizado (e.g. sckit-learn, MLJ, mlr3).

O maior problema da valida√ß√£o cruzada cl√°ssica √© que ela n√£o foi desenvolvida para dados geoespaciais. A exist√™ncia de correla√ß√£o entre duas localiza√ß√µes do dom√≠nio compromete a estimativa do erro que se torna **super otimista**.

Para ilustrar esse problema, tentaremos estimar o erro de qualquer um dos solvers (e.g. poitwise decision tree) utilizando o m√©todo CV. Precisamos definir o **n√∫mero de folds** e a **fun√ß√£o de perda**.

##### N√∫mero de folds $k$
O n√∫mero de folds geralmente √© escolhido em fun√ß√£o da quantidade de dados no dom√≠nio de origem e do recurso computacional dispon√≠vel. Como existem muitos exemplos (>300k) nos po√ßos `ONSHORE`, podemos escolher valores de $k$ em fun√ß√£o do custo computacional. Valores muito maiores que $k=20$ s√£o desnecessariamente caros computacionalmente:
"""

# ‚ïî‚ïê‚ï° 7c5beee4-c4bb-40a5-ab3e-c2fb88e363cb
k = 20

# ‚ïî‚ïê‚ï° 7204b07c-7ad3-4384-b41c-f214e040d280
md"""
##### Fun√ß√£o de perda $\mathcal{L}$
Uma fun√ß√£o de perda pode ser escolhida do pacote [LossFunctions.jl](https://github.com/JuliaML/LossFunctions.jl). Neste caso de classifica√ß√£o bin√°ria podemos escolher a fun√ß√£o `MissclassLoss()` que assume o valor `1` quando o exemplo √© classificado incorretamente pelo modelo e `0` quando a classifica√ß√£o √© correta:
"""

# ‚ïî‚ïê‚ï° 10454510-fcff-46d6-8e28-7800cc0bfd4d
‚Ñí = MisclassLoss()

# ‚ïî‚ïê‚ï° e4d731eb-e8a3-42d2-beae-54f053722503
md"""
Por fim, criamos o m√©todo de valida√ß√£o CV especificando o n√∫mero de folds e a fun√ß√£o de perda para cada vari√°vel de sa√≠da do problema:
"""

# ‚ïî‚ïê‚ï° 74ecd539-73e9-4fdc-ab35-4a58278ef5bf
CV = CrossValidation(20, loss = Dict(:FORMATION => ‚Ñí))

# ‚ïî‚ïê‚ï° 6dd4b8dd-7dd1-44b7-818a-f6461c9b619a
md"""
##### Estimativa CV

Em uma linha de c√≥digo, o GeoStats.jl se encarrega de particionar o dom√≠nio geoespacial, treinar os modelos em paralelo em cada fold, e combinar as estimativas de erro:
"""

# ‚ïî‚ïê‚ï° 56a82bee-08fc-4c17-9437-e105b2a3cb1c
md"""
Solver index: $(@bind index Scrubbable(1:length(solvers), default=1))
"""

# ‚ïî‚ïê‚ï° 7e1896be-7ae8-4b61-8f47-c147ee199bac
error(solvers[index], problem, CV)

# ‚ïî‚ïê‚ï° a183e138-60be-49ad-8b67-f780b46e9bb2
md"""
Podemos comparar a estimativa de erro obtida com o m√©todo CV com o erro real neste caso sint√©tico, e constatar o super otimismo da valida√ß√£o cruzada cl√°ssica:
"""

# ‚ïî‚ïê‚ï° f0f10827-7753-4f93-ba63-9b717e1e6ac9
begin
	# Solu√ß√£o geoespacial
	Œ©ÃÇ‚Çú = solutions[index]
	
	# Valor real da forma√ß√£o
	y  = Œ©‚Çú[:FORMATION]
	
	# Previs√£o da forma√ß√£o
	yÃÇ  = Œ©ÃÇ‚Çú[:FORMATION]
	
	# Taxa de misclassica√ß√£o real
	LossFunctions.value(‚Ñí, y, yÃÇ, AggMode.Mean())
end

# ‚ïî‚ïê‚ï° 7a790985-6c7d-422d-bcb2-f5ba8caf0322
md"""
#### Valida√ß√£o cruzada em blocos (BCV)
"""

# ‚ïî‚ïê‚ï° 551b332f-3601-472a-b44b-c9b74b199db4
html"""

<p align="center">

    <img src="https://i.postimg.cc/mkRzF40s/bcv.png">

</p>

<p align="center">

    <b>Figura 6</b>: Folds da valida√ß√£o cruzada em blocos.

</p>

"""

# ‚ïî‚ïê‚ï° c867fdb8-9b85-4413-8275-533e773fb466
md"""
#### Valida√ß√£o cruzada com raz√£o de densidade (BCV)
"""

# ‚ïî‚ïê‚ï° 141524ec-9f9d-4950-9881-8b5ddcaa95f8
html"""

<p align="center">

    <img src="https://i.postimg.cc/gJR4Wv92/drv.png">

</p>

<p align="center">

    <b>Figura 7</b>: Folds da valida√ß√£o cruzada com raz√£o de densidade.

</p>

"""

# ‚ïî‚ïê‚ï° Cell order:
# ‚ïü‚îÄ32f6d41e-3248-4549-9546-53b34d5aa7c6
# ‚ïü‚îÄ762a6e04-fcb7-4713-859d-fdbfe8ead1bc
# ‚ïü‚îÄ32429926-f6c3-44b8-b012-d2c67cad0b6d
# ‚ïü‚îÄ3c79e7aa-b316-4c4b-b44e-e73312085c20
# ‚ïü‚îÄ4a3fb559-73dd-41e0-8a11-993e5bf286bf
# ‚ïü‚îÄf3ff120d-940c-40c9-b9f6-24d4a0b3aec1
# ‚ïü‚îÄ1856e01b-2d55-448d-8bdf-e59825934193
# ‚ïü‚îÄ615e4ed2-f77f-4f38-a6c1-7f0c0f985d49
# ‚ïü‚îÄb89139a7-57da-4d9d-a791-c06edd5ab99d
# ‚ïü‚îÄ8301bda7-e4a1-442e-bdd4-ad5c7c9e0b46
# ‚ïü‚îÄ301d2074-a2d7-44dc-aeb6-29e69ca5348f
# ‚ïü‚îÄa0b00451-7418-4d60-812f-5c2a9b32cd4d
# ‚ï†‚ïêf4ad710d-f2a0-4110-8e6f-d76f181881ae
# ‚ïü‚îÄ29cf81d4-996e-4283-8d72-63d3ed1f55a7
# ‚ïü‚îÄfc3aac9b-ff0b-4b9b-a8d1-a073510cb4c1
# ‚ïü‚îÄ6f400014-4f12-42ec-8ee8-db181d82f656
# ‚ïü‚îÄa280a283-59c3-4728-9110-b91d5ea63568
# ‚ïü‚îÄbfdbec36-069d-422d-8f88-fd97f8d85455
# ‚ï†‚ïêb6b9f6db-5d69-496b-9862-bf7d6add901b
# ‚ïü‚îÄ2702b5c2-b0b8-4926-aabb-9e1a34feb1d6
# ‚ïü‚îÄc2fbca00-a248-4f9e-9754-08fd47225bed
# ‚ï†‚ïêb106e967-13c3-483d-bc53-9772c25947be
# ‚ï†‚ïêe912de0f-cab2-4e11-b0bd-6a9603a9e966
# ‚ïü‚îÄce132078-cfd3-4455-98b4-3297b1be405f
# ‚ïü‚îÄ4a3d8d5a-e429-4bc9-91ee-1de5aaa8444b
# ‚ïü‚îÄ4eadc228-7905-4328-ab01-f21339dd40aa
# ‚ïü‚îÄ3855a6d5-7b8a-487b-abad-288f9fc0152d
# ‚ï†‚ïêeb9d3014-65b2-44f7-8d33-445826e6974b
# ‚ïü‚îÄ4b41d46e-ccf0-4232-8ce8-f9520a90efea
# ‚ï†‚ïêa1c4fc51-1878-4c13-8d01-3642d23ee670
# ‚ïü‚îÄc10c7845-61ec-4275-b9a0-4934a7848e9b
# ‚ï†‚ïêd70ac330-0aae-4fae-91a2-159f1c1bc11f
# ‚ï†‚ïê44a77b1f-9d34-45f0-989c-ab03d3d2aaa9
# ‚ïü‚îÄ32f8bc26-97e4-4cfa-b064-eebe0403accb
# ‚ï†‚ïêdcc82e49-af10-4f9c-927d-1cf039a6185a
# ‚ï†‚ïê86694a19-f5c9-45a7-8f2b-ec63af5b9cdf
# ‚ï†‚ïê6d1b48f9-c7c6-461d-9908-f2a36de2694f
# ‚ïü‚îÄ4c76d345-1d77-4f7f-9fbe-2d4707d70b29
# ‚ïü‚îÄ06e19a21-5a4e-48c0-9030-9c6c43a3afdb
# ‚ïü‚îÄe3c46f60-b32e-4911-971f-230c87507f37
# ‚ïü‚îÄ0e168bfe-902b-4732-8ecb-a9a75b330bbb
# ‚ïü‚îÄbfbb10f9-364f-441a-872a-96753c3d2231
# ‚ïü‚îÄ89e8f272-8812-4e1e-8ab6-1cb7700c0fde
# ‚ï†‚ïê8ee75575-d2f2-409f-9016-dac048fc6ff6
# ‚ïü‚îÄa21d65cb-d369-4e9b-a1a6-53b06b09dc22
# ‚ï†‚ïêcb8d9a31-d415-45b7-a743-15c715dfd2a5
# ‚ïü‚îÄ8712e1ec-0b84-4fc4-a44e-6f5a91180b8b
# ‚ï†‚ïê59c355a1-34d5-415b-9e29-afcab5103576
# ‚ï†‚ïê340c939a-2a9b-475d-91ef-62effb2a8da3
# ‚ïü‚îÄ2c7442fa-5b8c-411d-b3f8-f0ed2ed00dc8
# ‚ï†‚ïêa7b23e9e-b3f3-4a8b-a5a7-dae05fd73bf1
# ‚ï†‚ïê777f4131-2cbb-4ba5-b786-d6175e3036a5
# ‚ïü‚îÄfbd3a1ec-214f-450f-9c2e-547df22157d3
# ‚ï†‚ïê55151073-083b-433c-96e0-5e51978e888f
# ‚ïü‚îÄ0250f930-ac62-4fdf-8e36-b79769974a25
# ‚ï†‚ïêa012ef03-64a4-44cb-95c2-a5f734a3f75d
# ‚ïü‚îÄ12112daa-17f1-445a-93e8-131c35cfb53d
# ‚ï†‚ïê10ab0262-00ef-4b77-8b6b-a43cf236a29d
# ‚ïü‚îÄ427d35b8-daf0-4d16-87e5-f8eb33e265fe
# ‚ïü‚îÄ1ec6e447-fe94-4288-9996-0ba42c8d6cb0
# ‚ï†‚ïê34f48c18-d452-4df4-a8f8-882bfc1db056
# ‚ïü‚îÄ2daa903b-af18-40ad-b9ce-0caf93b507c6
# ‚ï†‚ïêafa08349-eab0-4ed6-a0aa-cc3cb39a619d
# ‚ïü‚îÄb0843d5b-69eb-4a53-bff7-2d3bbd8b0057
# ‚ï†‚ïê9dd85a75-c1e3-418a-bb3e-7c8875e9c5dd
# ‚ïü‚îÄbd82b213-99b2-4ba7-997c-9ddbac69579c
# ‚ï†‚ïê3ba896bd-e569-40c3-9fa1-3e79db50bf45
# ‚ïü‚îÄf66e960b-e38f-4414-be79-09658eb5cf74
# ‚ï†‚ïêb70f5ab7-9790-4daf-a881-d75c602aaa67
# ‚ï†‚ïê5ec99dcc-58b4-4290-8f05-884ef11e464d
# ‚ïü‚îÄ78d9f9ba-1947-4bec-bc74-b895d084365e
# ‚ï†‚ïêe6e84f8b-e132-42a7-a0e4-1acd9006dbbb
# ‚ïü‚îÄ653ed159-838c-47d6-878e-0b2530cf7c52
# ‚ïü‚îÄda350067-a8fb-47bc-b9b8-b069e742383b
# ‚ï†‚ïêab970650-8dbd-442b-9a25-4cd871ecd336
# ‚ïü‚îÄ3e469cb8-745d-4f11-a6e7-814f29e1ccef
# ‚ï†‚ïê5b54c097-07b2-4c26-85b1-c7716cd98145
# ‚ïü‚îÄ7d6597a0-ae24-483a-a67f-dd6235acb25e
# ‚ïü‚îÄd10b3695-0f6d-406f-813d-17e76d47ba76
# ‚ïü‚îÄf96d976f-f40c-4ad2-8bbe-e45da5a3ae3d
# ‚ïü‚îÄ6ccd3492-a71d-4848-97e1-900614df7aa7
# ‚ï†‚ïê7c5beee4-c4bb-40a5-ab3e-c2fb88e363cb
# ‚ïü‚îÄ7204b07c-7ad3-4384-b41c-f214e040d280
# ‚ï†‚ïê10454510-fcff-46d6-8e28-7800cc0bfd4d
# ‚ïü‚îÄe4d731eb-e8a3-42d2-beae-54f053722503
# ‚ï†‚ïê74ecd539-73e9-4fdc-ab35-4a58278ef5bf
# ‚ïü‚îÄ6dd4b8dd-7dd1-44b7-818a-f6461c9b619a
# ‚ïü‚îÄ56a82bee-08fc-4c17-9437-e105b2a3cb1c
# ‚ï†‚ïê7e1896be-7ae8-4b61-8f47-c147ee199bac
# ‚ïü‚îÄa183e138-60be-49ad-8b67-f780b46e9bb2
# ‚ï†‚ïêf0f10827-7753-4f93-ba63-9b717e1e6ac9
# ‚ïü‚îÄ7a790985-6c7d-422d-bcb2-f5ba8caf0322
# ‚ïü‚îÄ551b332f-3601-472a-b44b-c9b74b199db4
# ‚ïü‚îÄc867fdb8-9b85-4413-8275-533e773fb466
# ‚ïü‚îÄ141524ec-9f9d-4950-9881-8b5ddcaa95f8
